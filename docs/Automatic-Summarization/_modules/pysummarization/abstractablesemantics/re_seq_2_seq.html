

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pysummarization.abstractablesemantics.re_seq_2_seq &#8212; pysummarization  documentation</title>
    <link rel="stylesheet" href="../../../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for pysummarization.abstractablesemantics.re_seq_2_seq</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="k">import</span> <span class="n">getLogger</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">pysummarization.abstractable_semantics</span> <span class="k">import</span> <span class="n">AbstractableSemantics</span>
<span class="kn">from</span> <span class="nn">pysummarization.vectorizable_token</span> <span class="k">import</span> <span class="n">VectorizableToken</span>

<span class="c1"># LSTM Graph which is-a `Synapse`.</span>
<span class="kn">from</span> <span class="nn">pydbm.synapse.recurrenttemporalgraph.lstm_graph</span> <span class="k">import</span> <span class="n">LSTMGraph</span> <span class="k">as</span> <span class="n">EncoderGraph</span>
<span class="kn">from</span> <span class="nn">pydbm.synapse.recurrenttemporalgraph.lstm_graph</span> <span class="k">import</span> <span class="n">LSTMGraph</span> <span class="k">as</span> <span class="n">DecoderGraph</span>
<span class="kn">from</span> <span class="nn">pydbm.synapse.recurrenttemporalgraph.lstm_graph</span> <span class="k">import</span> <span class="n">LSTMGraph</span> <span class="k">as</span> <span class="n">ReEncoderGraph</span>

<span class="c1"># Loss function.</span>
<span class="kn">from</span> <span class="nn">pydbm.loss.mean_squared_error</span> <span class="k">import</span> <span class="n">MeanSquaredError</span>

<span class="c1"># Adam as a Loss function.</span>
<span class="kn">from</span> <span class="nn">pydbm.optimization.optparams.nadam</span> <span class="k">import</span> <span class="n">Nadam</span> <span class="k">as</span> <span class="n">EncoderAdam</span>
<span class="kn">from</span> <span class="nn">pydbm.optimization.optparams.nadam</span> <span class="k">import</span> <span class="n">Nadam</span> <span class="k">as</span> <span class="n">DecoderAdam</span>
<span class="kn">from</span> <span class="nn">pydbm.optimization.optparams.nadam</span> <span class="k">import</span> <span class="n">Nadam</span> <span class="k">as</span> <span class="n">ReEncoderAdam</span>
<span class="c1"># Verification.</span>
<span class="kn">from</span> <span class="nn">pydbm.verification.verificate_function_approximation</span> <span class="k">import</span> <span class="n">VerificateFunctionApproximation</span>
<span class="c1"># LSTM model.</span>
<span class="kn">from</span> <span class="nn">pydbm.rnn.lstm_model</span> <span class="k">import</span> <span class="n">LSTMModel</span>
<span class="kn">from</span> <span class="nn">pydbm.rnn.lstm_model</span> <span class="k">import</span> <span class="n">LSTMModel</span> <span class="k">as</span> <span class="n">Encoder</span>
<span class="kn">from</span> <span class="nn">pydbm.rnn.lstm_model</span> <span class="k">import</span> <span class="n">LSTMModel</span> <span class="k">as</span> <span class="n">Decoder</span>
<span class="kn">from</span> <span class="nn">pydbm.rnn.lstm_model</span> <span class="k">import</span> <span class="n">LSTMModel</span> <span class="k">as</span> <span class="n">ReEncoder</span>
<span class="c1"># Logistic Function as activation function.</span>
<span class="kn">from</span> <span class="nn">pydbm.activation.logistic_function</span> <span class="k">import</span> <span class="n">LogisticFunction</span>
<span class="c1"># Tanh Function as activation function.</span>
<span class="kn">from</span> <span class="nn">pydbm.activation.tanh_function</span> <span class="k">import</span> <span class="n">TanhFunction</span>
<span class="c1"># Softmax Function as activation function.</span>
<span class="kn">from</span> <span class="nn">pydbm.activation.softmax_function</span> <span class="k">import</span> <span class="n">SoftmaxFunction</span>
<span class="c1"># Encoder/Decoder</span>
<span class="kn">from</span> <span class="nn">pydbm.rnn.encoder_decoder_controller</span> <span class="k">import</span> <span class="n">EncoderDecoderController</span>
<span class="c1"># Iterator/Generator.</span>
<span class="kn">from</span> <span class="nn">pydbm.cnn.feature_generator</span> <span class="k">import</span> <span class="n">FeatureGenerator</span>


<div class="viewcode-block" id="ReSeq2Seq"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq">[docs]</a><span class="k">class</span> <span class="nc">ReSeq2Seq</span><span class="p">(</span><span class="n">AbstractableSemantics</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A retrospective sequence-to-sequence learning(re-seq2seq).</span>

<span class="sd">    The concept of the re-seq2seq(Zhang, K. et al., 2018) provided inspiration to this library.</span>
<span class="sd">    This model is a new sequence learning model mainly in the field of Video Summarizations.</span>
<span class="sd">    &quot;The key idea behind re-seq2seq is to measure how well the machine-generated summary </span>
<span class="sd">    is similar to the original video in an abstract semantic space&quot; (Zhang, K. et al., 2018, p3).</span>

<span class="sd">    The encoder of a seq2seq model observes the original video and output feature points</span>
<span class="sd">    which represents the semantic meaning of the observed data points.</span>
<span class="sd">    Then the feature points is observed by the decoder of this model.</span>
<span class="sd">    Additionally, in the re-seq2seq model, the outputs of the decoder is propagated</span>
<span class="sd">    to a retrospective encoder, which infers feature points to represent the </span>
<span class="sd">    semantic meaning of the summary. &quot;If the summary preserves the important and </span>
<span class="sd">    relevant information in the original video, then we should expect that the </span>
<span class="sd">    two embeddings are similar (e.g. in Euclidean distance)&quot; (Zhang, K. et al., 2018, p3).</span>

<span class="sd">    This library refers to this intuitive insight above to apply the model to text summarizations.</span>
<span class="sd">    Like videos, semantic feature representation based on representation learning of manifolds </span>
<span class="sd">    is also possible in text summarizations.</span>
<span class="sd">    </span>
<span class="sd">    The intuition in the design of their loss function is also suggestive.</span>
<span class="sd">    &quot;The intuition behind our modeling is that the outputs should convey </span>
<span class="sd">    the same amount of information as the inputs. For summarization, </span>
<span class="sd">    this is precisely the goal: a good summary should be such that after viewing </span>
<span class="sd">    the summary, users would get about the same amount of information as if they </span>
<span class="sd">    had viewed the original video&quot; (Zhang, K. et al., 2018, p7).</span>

<span class="sd">    But the model in this library and Zhang, K. et al.(2018) are different in some respects</span>
<span class="sd">    from the relation with the specification of the Deep Learning library: [pydbm](https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern).</span>
<span class="sd">    First, Encoder/Decoder based on LSTM is not designed as a hierarchical structure. </span>
<span class="sd">    Second, it is possible to introduce regularization techniques which are not discussed in </span>
<span class="sd">    Zhang, K. et al.(2018) such as the dropout, the gradient clipping, and limitation of weights.</span>
<span class="sd">    Third, the regression loss function for matching summaries is simplified in terms of </span>
<span class="sd">    calculation efficiency in this library.</span>

<span class="sd">    References:</span>
<span class="sd">        - Zhang, K., Grauman, K., &amp; Sha, F. (2018). Retrospective Encoders for Video Summarization. In Proceedings of the European Conference on Computer Vision (ECCV) (pp. 383-399).</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Logs of accuracy.</span>
    <span class="n">__logs_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">margin_param</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">retrospective_lambda</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">retrospective_eta</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">encoder_decoder_controller</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">retrospective_encoder</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">weight_limit</span><span class="o">=</span><span class="mf">1e+10</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">pre_learning_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">grad_clip_threshold</span><span class="o">=</span><span class="mf">1e+10</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">bptt_tau</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">=</span><span class="mf">100.0</span>
    <span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Init.</span>

<span class="sd">        Args:</span>
<span class="sd">            margin_param:                   A margin parameter for the mismatched pairs penalty.</span>
<span class="sd">            retrospective_lambda:           Tradeoff parameter for loss function.</span>
<span class="sd">            retrospective_eta:              Tradeoff parameter for loss function.</span>
<span class="sd">            encoder_decoder_controller:     is-a `EncoderDecoderController`.</span>
<span class="sd">            retrospective_encoder:          is-a `LSTMModel` as a retrospective encoder(or re-encoder).</span>
<span class="sd">            input_neuron_count:             The number of units in input layers.</span>
<span class="sd">            hidden_neuron_count:            The number of units in hidden layers.</span>
<span class="sd">            weight_limit:                   Regularization for weights matrix to repeat multiplying </span>
<span class="sd">                                            the weights matrix and `0.9` until $\sum_{j=0}^{n}w_{ji}^2 &lt; weight\_limit$.</span>

<span class="sd">            dropout_rate:                   Probability of dropout.</span>
<span class="sd">            pre_learning_epochs:            The epochs in mini-batch pre-learning Encoder/Decoder.</span>
<span class="sd">                                            If this value is `0`, no pre-learning will be executed</span>
<span class="sd">                                            in this class&#39;s method `learn`. In this case, you should </span>
<span class="sd">                                            do pre-learning before calling `learn`.</span>

<span class="sd">            epochs:                         The epochs in mini-batch training Encoder/Decoder and retrospective encoder.</span>
<span class="sd">            batch_size:                     Batch size.</span>
<span class="sd">            learning_rate:                  Learning rate.</span>
<span class="sd">            learning_attenuate_rate:        Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>
<span class="sd">            attenuate_epoch:                Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>
<span class="sd">                                            Additionally, in relation to regularization,</span>
<span class="sd">                                            this class constrains weight matrixes every `attenuate_epoch`.</span>

<span class="sd">            grad_clip_threshold:            Threshold of the gradient clipping.</span>
<span class="sd">            seq_len:                        The length of sequneces in Decoder with Attention model.</span>
<span class="sd">            bptt_tau:                       Refereed maxinum step `t` in Backpropagation Through Time(BPTT).</span>
<span class="sd">                                            If `0`, this class referes all past data in BPTT.</span>

<span class="sd">            test_size_rate:                 Size of Test data set. If this value is `0`, the validation will not be executed.</span>
<span class="sd">            tol:                            Tolerance for the optimization.</span>
<span class="sd">                                            When the loss or score is not improving by at least tol </span>
<span class="sd">                                            for two consecutive iterations, convergence is considered </span>
<span class="sd">                                            to be reached and training stops.</span>

<span class="sd">            tld:                            Tolerance for deviation of loss.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">margin_param</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The type of `margin_param` must be `float`.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">margin_param</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The value of `margin_param` must be more than `0`.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__margin_param</span> <span class="o">=</span> <span class="n">margin_param</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retrospective_lambda</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retrospective_eta</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The type of `retrospective_lambda` and `retrospective_eta` must be `float`.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">retrospective_lambda</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">retrospective_eta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The values of `retrospective_lambda` and `retrospective_eta` must be more then `0`.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">retrospective_lambda</span> <span class="o">+</span> <span class="n">retrospective_eta</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The sum of `retrospective_lambda` and `retrospective_eta` must be `1`.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_lambda</span> <span class="o">=</span> <span class="n">retrospective_lambda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_eta</span> <span class="o">=</span> <span class="n">retrospective_eta</span>

        <span class="k">if</span> <span class="n">encoder_decoder_controller</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__build_encoder_decoder_controller</span><span class="p">(</span>
                <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span><span class="p">,</span>
                <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
                <span class="n">weight_limit</span><span class="o">=</span><span class="n">weight_limit</span><span class="p">,</span>
                <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="n">pre_learning_epochs</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">attenuate_epoch</span><span class="o">=</span><span class="n">attenuate_epoch</span><span class="p">,</span>
                <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="n">learning_attenuate_rate</span><span class="p">,</span>
                <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
                <span class="n">bptt_tau</span><span class="o">=</span><span class="n">bptt_tau</span><span class="p">,</span>
                <span class="n">test_size_rate</span><span class="o">=</span><span class="n">test_size_rate</span><span class="p">,</span>
                <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">tld</span><span class="o">=</span><span class="n">tld</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder_decoder_controller</span><span class="p">,</span> <span class="n">EncoderDecoderController</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">retrospective_encoder</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">retrospective_encoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__build_retrospective_encoder</span><span class="p">(</span>
                <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span><span class="p">,</span>
                <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
                <span class="n">weight_limit</span><span class="o">=</span><span class="n">weight_limit</span><span class="p">,</span>
                <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">bptt_tau</span><span class="o">=</span><span class="n">bptt_tau</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retrospective_encoder</span><span class="p">,</span> <span class="n">LSTMModel</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span> <span class="o">=</span> <span class="n">encoder_decoder_controller</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span> <span class="o">=</span> <span class="n">retrospective_encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__epochs</span> <span class="o">=</span> <span class="n">epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__attenuate_epoch</span> <span class="o">=</span> <span class="n">attenuate_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__learning_attenuate_rate</span> <span class="o">=</span> <span class="n">learning_attenuate_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__grad_clip_threshold</span> <span class="o">=</span> <span class="n">grad_clip_threshold</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__test_size_rate</span> <span class="o">=</span> <span class="n">test_size_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__pre_learning_epochs</span> <span class="o">=</span> <span class="n">pre_learning_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tol</span> <span class="o">=</span> <span class="n">tol</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__tld</span> <span class="o">=</span> <span class="n">tld</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__input_neuron_count</span> <span class="o">=</span> <span class="n">input_neuron_count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__hidden_neuron_count</span> <span class="o">=</span> <span class="n">hidden_neuron_count</span>

        <span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pysummarization&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logs_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">__build_encoder_decoder_controller</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">weight_limit</span><span class="o">=</span><span class="mf">1e+15</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">bptt_tau</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
        <span class="n">tld</span><span class="o">=</span><span class="mf">100.0</span>
    <span class="p">):</span>
        <span class="n">encoder_graph</span> <span class="o">=</span> <span class="n">EncoderGraph</span><span class="p">()</span>

        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">observed_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">input_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">forget_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">output_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">hidden_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">output_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>

        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">create_rnn_cells</span><span class="p">(</span>
            <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span><span class="p">,</span>
            <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="n">output_neuron_count</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">encoder_opt_params</span> <span class="o">=</span> <span class="n">EncoderAdam</span><span class="p">()</span>
        <span class="n">encoder_opt_params</span><span class="o">.</span><span class="n">weight_limit</span> <span class="o">=</span> <span class="n">weight_limit</span>
        <span class="n">encoder_opt_params</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">encoder_graph</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">bptt_tau</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">opt_params</span><span class="o">=</span><span class="n">encoder_opt_params</span><span class="p">,</span>
            <span class="n">verificatable_result</span><span class="o">=</span><span class="n">VerificateFunctionApproximation</span><span class="p">(),</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">tld</span><span class="o">=</span><span class="n">tld</span>
        <span class="p">)</span>

        <span class="n">decoder_graph</span> <span class="o">=</span> <span class="n">DecoderGraph</span><span class="p">()</span>

        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">observed_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">input_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">forget_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">output_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">hidden_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">output_activating_function</span> <span class="o">=</span> <span class="n">SoftmaxFunction</span><span class="p">()</span>

        <span class="n">decoder_graph</span><span class="o">.</span><span class="n">create_rnn_cells</span><span class="p">(</span>
            <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="n">output_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span>
        <span class="p">)</span>
        <span class="n">decoder_opt_params</span> <span class="o">=</span> <span class="n">DecoderAdam</span><span class="p">()</span>
        <span class="n">decoder_opt_params</span><span class="o">.</span><span class="n">weight_limit</span> <span class="o">=</span> <span class="n">weight_limit</span>
        <span class="n">decoder_opt_params</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="n">decoder</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">decoder_graph</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
            <span class="n">bptt_tau</span><span class="o">=</span><span class="n">bptt_tau</span><span class="p">,</span>
            <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">opt_params</span><span class="o">=</span><span class="n">decoder_opt_params</span><span class="p">,</span>
            <span class="n">verificatable_result</span><span class="o">=</span><span class="n">VerificateFunctionApproximation</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="n">EncoderDecoderController</span><span class="p">(</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="n">learning_attenuate_rate</span><span class="p">,</span>
            <span class="n">attenuate_epoch</span><span class="o">=</span><span class="n">attenuate_epoch</span><span class="p">,</span>
            <span class="n">test_size_rate</span><span class="o">=</span><span class="n">test_size_rate</span><span class="p">,</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">verificatable_result</span><span class="o">=</span><span class="n">VerificateFunctionApproximation</span><span class="p">(),</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">tld</span><span class="o">=</span><span class="n">tld</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">encoder_decoder_controller</span>

    <span class="k">def</span> <span class="nf">__build_retrospective_encoder</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">weight_limit</span><span class="o">=</span><span class="mf">1e+10</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">bptt_tau</span><span class="o">=</span><span class="mi">8</span>
    <span class="p">):</span>
        <span class="n">encoder_graph</span> <span class="o">=</span> <span class="n">ReEncoderGraph</span><span class="p">()</span>

        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">observed_activating_function</span> <span class="o">=</span> <span class="n">TanhFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">input_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">forget_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">output_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">hidden_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">output_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>

        <span class="n">encoder_graph</span><span class="o">.</span><span class="n">create_rnn_cells</span><span class="p">(</span>
            <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span><span class="p">,</span>
            <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="n">output_neuron_count</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">encoder_opt_params</span> <span class="o">=</span> <span class="n">EncoderAdam</span><span class="p">()</span>
        <span class="n">encoder_opt_params</span><span class="o">.</span><span class="n">weight_limit</span> <span class="o">=</span> <span class="n">weight_limit</span>
        <span class="n">encoder_opt_params</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span>

        <span class="n">encoder</span> <span class="o">=</span> <span class="n">ReEncoder</span><span class="p">(</span>
            <span class="n">graph</span><span class="o">=</span><span class="n">encoder_graph</span><span class="p">,</span>
            <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
            <span class="n">bptt_tau</span><span class="o">=</span><span class="n">bptt_tau</span><span class="p">,</span>
            <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
            <span class="n">opt_params</span><span class="o">=</span><span class="n">encoder_opt_params</span><span class="p">,</span>
            <span class="n">verificatable_result</span><span class="o">=</span><span class="n">VerificateFunctionApproximation</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">encoder</span>

<div class="viewcode-block" id="ReSeq2Seq.learn"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn">[docs]</a>    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">,</span> <span class="n">target_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Training the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            observed_arr:       `np.ndarray` of observed data points.</span>
<span class="sd">            target_arr:         `np.ndarray` of target labeled data.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># Pre-learning.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pre_learning_epochs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">)</span>

        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span>
        <span class="n">row_o</span> <span class="o">=</span> <span class="n">observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">row_t</span> <span class="o">=</span> <span class="n">target_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">row_t</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">row_t</span> <span class="o">!=</span> <span class="n">row_o</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The row of `target_arr` must be equivalent to the row of `observed_arr`.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">row_t</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">target_arr</span> <span class="o">=</span> <span class="n">observed_arr</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">target_arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">target_arr</span> <span class="o">=</span> <span class="n">target_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">target_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">target_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__test_size_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">round</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">__test_size_rate</span><span class="p">)</span> <span class="o">*</span> <span class="n">observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">train_index</span><span class="p">)))</span>
            <span class="n">train_observed_arr</span> <span class="o">=</span> <span class="n">observed_arr</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
            <span class="n">test_observed_arr</span> <span class="o">=</span> <span class="n">observed_arr</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="n">train_target_arr</span> <span class="o">=</span> <span class="n">target_arr</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
            <span class="n">test_target_arr</span> <span class="o">=</span> <span class="n">target_arr</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_observed_arr</span> <span class="o">=</span> <span class="n">observed_arr</span>
            <span class="n">train_target_arr</span> <span class="o">=</span> <span class="n">target_arr</span>

        <span class="n">encoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">decoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">re_encoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__memory_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">min_loss</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__epochs</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attenuate_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_attenuate_rate</span>

                <span class="n">rand_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__batch_size</span><span class="p">)</span>
                <span class="n">batch_observed_arr</span> <span class="o">=</span> <span class="n">train_observed_arr</span><span class="p">[</span><span class="n">rand_index</span><span class="p">]</span>
                <span class="n">batch_target_arr</span> <span class="o">=</span> <span class="n">train_target_arr</span><span class="p">[</span><span class="n">rand_index</span><span class="p">]</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">batch_observed_arr</span><span class="p">)</span>
                    <span class="n">delta_arr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tld</span><span class="p">:</span>
                            <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">True</span>

                    <span class="k">if</span> <span class="n">remember_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
                            <span class="n">encoder_best_params_list</span><span class="p">,</span>
                            <span class="n">decoder_best_params_list</span><span class="p">,</span>
                            <span class="n">re_encoder_best_params_list</span>
                        <span class="p">)</span>
                        <span class="c1"># Re-try.</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">batch_observed_arr</span><span class="p">)</span>
                        <span class="n">delta_arr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">re_encoder_grads_list</span><span class="p">,</span> <span class="n">decoder_grads_list</span><span class="p">,</span> <span class="n">encoder_delta_arr</span><span class="p">,</span> <span class="n">encoder_grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">back_propagation</span><span class="p">(</span><span class="n">delta_arr</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                        <span class="n">re_encoder_grads_list</span><span class="p">,</span>
                        <span class="n">decoder_grads_list</span><span class="p">,</span> 
                        <span class="n">encoder_grads_list</span><span class="p">,</span> 
                        <span class="n">learning_rate</span><span class="p">,</span> 
                        <span class="n">epoch</span>
                    <span class="p">)</span>

                    <span class="k">if</span> <span class="n">min_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_loss</span> <span class="o">&gt;</span> <span class="n">loss</span><span class="p">:</span>
                        <span class="n">min_loss</span> <span class="o">=</span> <span class="n">loss</span>
                        
                        <span class="n">encoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="n">decoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="n">re_encoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Best params are updated.&quot;</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

                <span class="k">except</span> <span class="ne">FloatingPointError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__epochs</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="s2">&quot;Underflow occurred when the parameters are being updated. Because of early stopping, this error is catched and the parameter is not updated.&quot;</span>
                        <span class="p">)</span>
                        <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="s2">&quot;Underflow occurred when the parameters are being updated.&quot;</span>
                        <span class="p">)</span>
                        <span class="k">raise</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__test_size_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">rand_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">test_observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__batch_size</span><span class="p">)</span>
                    <span class="n">test_batch_observed_arr</span> <span class="o">=</span> <span class="n">test_observed_arr</span><span class="p">[</span><span class="n">rand_index</span><span class="p">]</span>
                    <span class="n">test_batch_target_arr</span> <span class="o">=</span> <span class="n">test_target_arr</span><span class="p">[</span><span class="n">rand_index</span><span class="p">]</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_batch_observed_arr</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">test_loss</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tld</span><span class="p">:</span>
                            <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">True</span>

                    <span class="k">if</span> <span class="n">remember_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
                            <span class="n">encoder_best_params_list</span><span class="p">,</span> 
                            <span class="n">decoder_best_params_list</span><span class="p">,</span>
                            <span class="n">re_encoder_best_params_list</span>
                        <span class="p">)</span>
                        <span class="c1"># Re-try.</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_batch_observed_arr</span><span class="p">)</span>
                        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__verificate_retrospective_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

                <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">loss_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tol</span><span class="p">:</span>
                    <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
                <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Interrupt.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eary_stop_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Early stopping.&quot;</span><span class="p">)</span>
            <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
            <span class="n">encoder_best_params_list</span><span class="p">,</span> 
            <span class="n">decoder_best_params_list</span><span class="p">,</span>
            <span class="n">re_encoder_best_params_list</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;end. &quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ReSeq2Seq.learn_generated"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn_generated">[docs]</a>    <span class="k">def</span> <span class="nf">learn_generated</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feature_generator</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Learn features generated by `FeatureGenerator`.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            feature_generator:    is-a `FeatureGenerator`.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feature_generator</span><span class="p">,</span> <span class="n">FeatureGenerator</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;The type of `feature_generator` must be `FeatureGenerator`.&quot;</span><span class="p">)</span>

        <span class="c1"># Pre-learning.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pre_learning_epochs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">learn_generated</span><span class="p">(</span><span class="n">feature_generator</span><span class="p">)</span>

        <span class="n">learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span>

        <span class="n">encoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">decoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">re_encoder_best_params_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__memory_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">loss_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">min_loss</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">batch_observed_arr</span><span class="p">,</span> <span class="n">batch_target_arr</span><span class="p">,</span> <span class="n">test_batch_observed_arr</span><span class="p">,</span> <span class="n">test_batch_target_arr</span> <span class="ow">in</span> <span class="n">feature_generator</span><span class="o">.</span><span class="n">generate</span><span class="p">():</span>
                <span class="n">epoch</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="p">((</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attenuate_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_attenuate_rate</span>

                <span class="k">try</span><span class="p">:</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">batch_observed_arr</span><span class="p">)</span>
                    <span class="n">delta_arr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tld</span><span class="p">:</span>
                            <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">True</span>

                    <span class="k">if</span> <span class="n">remember_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
                            <span class="n">encoder_best_params_list</span><span class="p">,</span>
                            <span class="n">decoder_best_params_list</span><span class="p">,</span>
                            <span class="n">re_encoder_best_params_list</span>
                        <span class="p">)</span>
                        <span class="c1"># Re-try.</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">batch_observed_arr</span><span class="p">)</span>
                        <span class="n">delta_arr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">re_encoder_grads_list</span><span class="p">,</span> <span class="n">decoder_grads_list</span><span class="p">,</span> <span class="n">encoder_delta_arr</span><span class="p">,</span> <span class="n">encoder_grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">back_propagation</span><span class="p">(</span><span class="n">delta_arr</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                        <span class="n">re_encoder_grads_list</span><span class="p">,</span>
                        <span class="n">decoder_grads_list</span><span class="p">,</span> 
                        <span class="n">encoder_grads_list</span><span class="p">,</span> 
                        <span class="n">learning_rate</span><span class="p">,</span> 
                        <span class="n">epoch</span>
                    <span class="p">)</span>

                    <span class="k">if</span> <span class="n">min_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">min_loss</span> <span class="o">&gt;</span> <span class="n">loss</span><span class="p">:</span>
                        <span class="n">min_loss</span> <span class="o">=</span> <span class="n">loss</span>
                        
                        <span class="n">encoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="n">decoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="n">re_encoder_best_params_list</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span>
                        <span class="p">]</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Best params are updated.&quot;</span><span class="p">)</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

                <span class="k">except</span> <span class="ne">FloatingPointError</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__epochs</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="s2">&quot;Underflow occurred when the parameters are being updated. Because of early stopping, this error is catched and the parameter is not updated.&quot;</span>
                        <span class="p">)</span>
                        <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                            <span class="s2">&quot;Underflow occurred when the parameters are being updated.&quot;</span>
                        <span class="p">)</span>
                        <span class="k">raise</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__test_size_rate</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_batch_observed_arr</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">test_loss</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)))</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tld</span><span class="p">:</span>
                            <span class="n">remember_flag</span> <span class="o">=</span> <span class="kc">True</span>

                    <span class="k">if</span> <span class="n">remember_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
                            <span class="n">encoder_best_params_list</span><span class="p">,</span> 
                            <span class="n">decoder_best_params_list</span><span class="p">,</span>
                            <span class="n">re_encoder_best_params_list</span>
                        <span class="p">)</span>
                        <span class="c1"># Re-try.</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_batch_observed_arr</span><span class="p">)</span>
                        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__verificate_retrospective_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">hidden_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">cec_activity_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([])</span>

                <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="nb">abs</span><span class="p">(</span><span class="n">loss</span> <span class="o">-</span> <span class="n">loss_list</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__tol</span><span class="p">:</span>
                    <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="k">break</span>
                <span class="n">loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Interrupt.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eary_stop_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Early stopping.&quot;</span><span class="p">)</span>
            <span class="n">eary_stop_flag</span> <span class="o">=</span> <span class="kc">False</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">__remember_best_params</span><span class="p">(</span>
            <span class="n">encoder_best_params_list</span><span class="p">,</span> 
            <span class="n">decoder_best_params_list</span><span class="p">,</span>
            <span class="n">re_encoder_best_params_list</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__change_inferencing_mode</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;end. &quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="ReSeq2Seq.inference"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.inference">[docs]</a>    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Infernece by the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            observed_arr:       `np.ndarray` of observed data points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of inferenced feature points.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">decoded_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">)</span>
        <span class="n">encoded_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">get_feature_points</span><span class="p">()</span>
        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">decoded_arr</span><span class="p">)</span>
        <span class="n">re_encoded_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">get_feature_points</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="n">observed_arr</span><span class="p">,</span> <span class="n">encoded_arr</span><span class="p">,</span> <span class="n">decoded_arr</span><span class="p">,</span> <span class="n">re_encoded_arr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re_encoded_arr</span></div>

<div class="viewcode-block" id="ReSeq2Seq.summarize"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.summarize">[docs]</a>    <span class="k">def</span> <span class="nf">summarize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_arr</span><span class="p">,</span> <span class="n">vectorizable_token</span><span class="p">,</span> <span class="n">sentence_list</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Summarize input document.</span>

<span class="sd">        Args:</span>
<span class="sd">            test_arr:               `np.ndarray` of observed data points..</span>
<span class="sd">            vectorizable_token:     is-a `VectorizableToken`.</span>
<span class="sd">            sentence_list:          `list` of all sentences.</span>
<span class="sd">            limit:                  The number of selected abstract sentence.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            `list` of `str` of abstract sentences.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vectorizable_token</span><span class="p">,</span> <span class="n">VectorizableToken</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>

        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_arr</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">loss_arr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_retrospective_loss</span><span class="p">()</span>

        <span class="n">loss_list</span> <span class="o">=</span> <span class="n">loss_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="n">abstract_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">limit</span><span class="p">):</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">loss_arr</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">loss_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">loss_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">loss_list</span><span class="p">)</span>

            <span class="n">seq_arr</span> <span class="o">=</span> <span class="n">test_arr</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">token_arr</span> <span class="o">=</span> <span class="n">vectorizable_token</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">seq_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">s</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">token_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">_s</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">token_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

            <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentence</span> <span class="ow">or</span> <span class="n">_s</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
                    <span class="n">abstract_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
                    <span class="n">abstract_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">abstract_list</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">abstract_list</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">abstract_list</span></div>

<div class="viewcode-block" id="ReSeq2Seq.back_propagation"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.back_propagation">[docs]</a>    <span class="k">def</span> <span class="nf">back_propagation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">delta_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Back propagation.</span>

<span class="sd">        Args:</span>
<span class="sd">            delta_output_arr:    Delta.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple data.</span>
<span class="sd">            - decoder&#39;s `list` of gradations,</span>
<span class="sd">            - encoder&#39;s `np.ndarray` of Delta, </span>
<span class="sd">            - encoder&#39;s `list` of gradations.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">re_encoder_delta_arr</span><span class="p">,</span> <span class="n">delta_hidden_arr</span><span class="p">,</span> <span class="n">re_encoder_grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">hidden_back_propagate</span><span class="p">(</span>
            <span class="n">delta_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">re_encoder_grads_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">re_encoder_grads_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">observed_arr</span><span class="p">,</span> <span class="n">encoded_arr</span><span class="p">,</span> <span class="n">decoded_arr</span><span class="p">,</span> <span class="n">re_encoded_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_tuple</span>
        <span class="n">delta_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">computable_loss</span><span class="o">.</span><span class="n">compute_delta</span><span class="p">(</span>
            <span class="n">decoded_arr</span><span class="p">,</span> 
            <span class="n">observed_arr</span>
        <span class="p">)</span>
        <span class="n">delta_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">re_encoder_delta_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">decoder_grads_list</span><span class="p">,</span> <span class="n">encoder_delta_arr</span><span class="p">,</span> <span class="n">encoder_grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">back_propagation</span><span class="p">(</span>
            <span class="n">delta_arr</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">re_encoder_grads_list</span><span class="p">,</span> <span class="n">decoder_grads_list</span><span class="p">,</span> <span class="n">encoder_delta_arr</span><span class="p">,</span> <span class="n">encoder_grads_list</span></div>

<div class="viewcode-block" id="ReSeq2Seq.optimize"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.optimize">[docs]</a>    <span class="k">def</span> <span class="nf">optimize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">re_encoder_grads_list</span><span class="p">,</span>
        <span class="n">decoder_grads_list</span><span class="p">,</span>
        <span class="n">encoder_grads_list</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">,</span>
        <span class="n">epoch</span>
    <span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Back propagation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            re_encoder_grads_list:  re-encoder&#39;s `list` of graduations.</span>
<span class="sd">            decoder_grads_list:     decoder&#39;s `list` of graduations.</span>
<span class="sd">            encoder_grads_list:     encoder&#39;s `list` of graduations.</span>
<span class="sd">            learning_rate:          Learning rate.</span>
<span class="sd">            epoch:                  Now epoch.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">re_encoder_grads_list</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
            <span class="n">decoder_grads_list</span><span class="p">,</span>
            <span class="n">encoder_grads_list</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">epoch</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ReSeq2Seq.compute_retrospective_loss"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.compute_retrospective_loss">[docs]</a>    <span class="k">def</span> <span class="nf">compute_retrospective_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Compute retrospective loss.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The tuple data.</span>
<span class="sd">            - `np.ndarray` of delta.</span>
<span class="sd">            - `np.ndarray` of losses of each batch.</span>
<span class="sd">            - float of loss of all batch.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">observed_arr</span><span class="p">,</span> <span class="n">encoded_arr</span><span class="p">,</span> <span class="n">decoded_arr</span><span class="p">,</span> <span class="n">re_encoded_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_tuple</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">observed_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__input_neuron_count</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">__hidden_neuron_count</span><span class="p">:</span>
            <span class="n">target_arr</span> <span class="o">=</span> <span class="n">encoded_arr</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">observed_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">summary_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">decoded_arr</span> <span class="o">-</span> <span class="n">target_arr</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For each batch, draw a samples from the Uniform distribution.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__input_neuron_count</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__hidden_neuron_count</span><span class="p">:</span>
                <span class="n">all_dim_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__input_neuron_count</span><span class="p">)</span>
                <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">all_dim_arr</span><span class="p">)</span>
                <span class="n">choiced_dim_arr</span> <span class="o">=</span> <span class="n">all_dim_arr</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">__hidden_neuron_count</span><span class="p">]</span>
                <span class="n">target_arr</span> <span class="o">=</span> <span class="n">encoded_arr</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">choiced_dim_arr</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">summary_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">decoded_arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">choiced_dim_arr</span><span class="p">]</span> <span class="o">-</span> <span class="n">target_arr</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">all_dim_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__hidden_neuron_count</span><span class="p">)</span>
                <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">all_dim_arr</span><span class="p">)</span>
                <span class="n">choiced_dim_arr</span> <span class="o">=</span> <span class="n">all_dim_arr</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">__input_neuron_count</span><span class="p">]</span>
                <span class="n">target_arr</span> <span class="o">=</span> <span class="n">encoded_arr</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">choiced_dim_arr</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">observed_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">summary_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">decoded_arr</span> <span class="o">-</span> <span class="n">target_arr</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

        <span class="n">summary_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">summary_delta_arr</span><span class="p">)</span>
        <span class="n">summary_delta_arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">summary_delta_arr</span> <span class="o">-</span> <span class="n">summary_delta_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">summary_delta_arr</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-08</span><span class="p">)</span>

        <span class="n">match_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">re_encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">match_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">match_delta_arr</span><span class="p">)</span>
        <span class="n">match_delta_arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">match_delta_arr</span> <span class="o">-</span> <span class="n">match_delta_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">match_delta_arr</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-08</span><span class="p">)</span>

        <span class="n">other_encoded_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nansum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                        <span class="mi">0</span><span class="p">,</span>
                        <span class="n">encoded_arr</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">re_encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                            <span class="n">re_encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                            <span class="mi">1</span><span class="p">,</span> 
                            <span class="n">re_encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="p">),</span>
                    <span class="mi">2</span>
                <span class="p">)</span>
            <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">__margin_param</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">other_encoded_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">other_encoded_delta_arr</span><span class="p">)</span>
        <span class="n">other_encoded_delta_arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">other_encoded_delta_arr</span> <span class="o">-</span> <span class="n">other_encoded_delta_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">other_encoded_delta_arr</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-08</span><span class="p">)</span>

        <span class="n">other_re_encoded_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nansum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span>
                        <span class="mi">0</span><span class="p">,</span> 
                        <span class="n">encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                            <span class="n">encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="mi">1</span><span class="p">,</span>
                            <span class="n">encoded_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">)</span> <span class="o">-</span> <span class="n">re_encoded_arr</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> 
                    <span class="p">),</span>
                    <span class="mi">2</span>
                <span class="p">)</span>
            <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">__margin_param</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">other_encoded_delta_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">other_encoded_delta_arr</span><span class="p">)</span>
        <span class="n">other_re_encoded_delta_arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">other_re_encoded_delta_arr</span> <span class="o">-</span> <span class="n">other_re_encoded_delta_arr</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">other_re_encoded_delta_arr</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-08</span><span class="p">)</span>

        <span class="n">mismatch_delta_arr</span> <span class="o">=</span> <span class="p">(</span><span class="n">match_delta_arr</span> <span class="o">-</span> <span class="n">other_encoded_delta_arr</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">match_delta_arr</span> <span class="o">-</span> <span class="n">other_re_encoded_delta_arr</span><span class="p">)</span>

        <span class="n">delta_arr</span> <span class="o">=</span> <span class="n">summary_delta_arr</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_lambda</span> <span class="o">*</span> <span class="n">match_delta_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_eta</span> <span class="o">*</span> <span class="n">mismatch_delta_arr</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">delta_arr</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">v</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">__grad_clip_threshold</span><span class="p">:</span>
            <span class="n">delta_arr</span> <span class="o">=</span> <span class="n">delta_arr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">__grad_clip_threshold</span> <span class="o">/</span> <span class="n">v</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">delta_arr</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">loss_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">delta_arr</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">delta_arr</span><span class="p">,</span> <span class="n">loss_arr</span><span class="p">,</span> <span class="n">loss</span></div>

    <span class="k">def</span> <span class="nf">__change_inferencing_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inferencing_mode</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Change dropout rate in Encoder/Decoder.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            dropout_rate:   The probalibity of dropout.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">opt_params</span><span class="o">.</span><span class="n">inferencing_mode</span> <span class="o">=</span> <span class="n">inferencing_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">opt_params</span><span class="o">.</span><span class="n">inferencing_mode</span> <span class="o">=</span> <span class="n">inferencing_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">opt_params</span><span class="o">.</span><span class="n">inferencing_mode</span> <span class="o">=</span> <span class="n">inferencing_mode</span>

    <span class="k">def</span> <span class="nf">__remember_best_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_best_params_list</span><span class="p">,</span> <span class="n">decoder_best_params_list</span><span class="p">,</span> <span class="n">re_encoder_best_params_list</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Remember best parameters.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            encoder_best_params_list:    `list` of encoder&#39;s parameters.</span>
<span class="sd">            decoder_best_params_list:    `list` of decoder&#39;s parameters.</span>
<span class="sd">            re_encoder_best_params_list: `list` of re-decoder&#39;s parameters.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoder_best_params_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">decoder_best_params_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span> <span class="o">=</span> <span class="n">encoder_best_params_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span> <span class="o">=</span> <span class="n">encoder_best_params_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span> <span class="o">=</span> <span class="n">encoder_best_params_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span> <span class="o">=</span> <span class="n">decoder_best_params_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span> <span class="o">=</span> <span class="n">decoder_best_params_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span> <span class="o">=</span> <span class="n">decoder_best_params_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_hidden_arr</span> <span class="o">=</span> <span class="n">re_encoder_best_params_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">weights_lstm_observed_arr</span> <span class="o">=</span> <span class="n">re_encoder_best_params_list</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">lstm_bias_arr</span> <span class="o">=</span> <span class="n">re_encoder_best_params_list</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Best params are saved.&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__verificate_retrospective_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">test_loss</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Epoch: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__logs_tuple_list</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;Loss: &quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;Training: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; Test: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
        <span class="p">)</span>        
        <span class="bp">self</span><span class="o">.</span><span class="n">__logs_tuple_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="n">train_loss</span><span class="p">,</span>
                <span class="n">test_loss</span>
            <span class="p">)</span>
        <span class="p">)</span>

<div class="viewcode-block" id="ReSeq2Seq.get_logs_arr"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_logs_arr">[docs]</a>    <span class="k">def</span> <span class="nf">get_logs_arr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__logs_tuple_list</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="ReSeq2Seq.set_readonly"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.set_readonly">[docs]</a>    <span class="k">def</span> <span class="nf">set_readonly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; setter &#39;&#39;&#39;</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span></div>
    
    <span class="n">logs_arr</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_logs_arr</span><span class="p">,</span> <span class="n">set_readonly</span><span class="p">)</span>

<div class="viewcode-block" id="ReSeq2Seq.get_encoder_decoder_controller"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_encoder_decoder_controller">[docs]</a>    <span class="k">def</span> <span class="nf">get_encoder_decoder_controller</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span></div>
    
    <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_encoder_decoder_controller</span><span class="p">,</span> <span class="n">set_readonly</span><span class="p">)</span>

<div class="viewcode-block" id="ReSeq2Seq.get_retrospective_encoder"><a class="viewcode-back" href="../../../pysummarization.abstractablesemantics.html#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_retrospective_encoder">[docs]</a>    <span class="k">def</span> <span class="nf">get_retrospective_encoder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__retrospective_encoder</span></div>
    
    <span class="n">retrospective_encoder</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_retrospective_encoder</span><span class="p">,</span> <span class="n">set_readonly</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>