

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pygan.generativemodel.lstm_model &#8212; pygan  documentation</title>
    <link rel="stylesheet" href="../../../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">pygan  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for pygan.generativemodel.lstm_model</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="k">import</span> <span class="n">getLogger</span>

<span class="kn">from</span> <span class="nn">pygan.generative_model</span> <span class="k">import</span> <span class="n">GenerativeModel</span>
<span class="kn">from</span> <span class="nn">pygan.true_sampler</span> <span class="k">import</span> <span class="n">TrueSampler</span>

<span class="c1"># LSTM Graph which is-a `Synapse`.</span>
<span class="kn">from</span> <span class="nn">pydbm.synapse.recurrenttemporalgraph.lstm_graph</span> <span class="k">import</span> <span class="n">LSTMGraph</span>
<span class="c1"># Loss function.</span>
<span class="kn">from</span> <span class="nn">pydbm.loss.interface.computable_loss</span> <span class="k">import</span> <span class="n">ComputableLoss</span>
<span class="kn">from</span> <span class="nn">pydbm.loss.mean_squared_error</span> <span class="k">import</span> <span class="n">MeanSquaredError</span>
<span class="c1"># SGD.</span>
<span class="kn">from</span> <span class="nn">pydbm.optimization.optparams.sgd</span> <span class="k">import</span> <span class="n">SGD</span>
<span class="c1"># Verification.</span>
<span class="kn">from</span> <span class="nn">pydbm.verification.verificate_function_approximation</span> <span class="k">import</span> <span class="n">VerificateFunctionApproximation</span>

<span class="kn">from</span> <span class="nn">pydbm.activation.interface.activating_function_interface</span> <span class="k">import</span> <span class="n">ActivatingFunctionInterface</span>
<span class="c1"># Logistic Function as activation function.</span>
<span class="kn">from</span> <span class="nn">pydbm.activation.logistic_function</span> <span class="k">import</span> <span class="n">LogisticFunction</span>
<span class="c1"># Tanh Function as activation function.</span>
<span class="kn">from</span> <span class="nn">pydbm.activation.tanh_function</span> <span class="k">import</span> <span class="n">TanhFunction</span>

<span class="kn">from</span> <span class="nn">pydbm.rnn.lstm_model</span> <span class="k">import</span> <span class="n">LSTMModel</span> <span class="k">as</span> <span class="n">LSTM</span>


<div class="viewcode-block" id="LSTMModel"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel">[docs]</a><span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">GenerativeModel</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    LSTM as a Generator.</span>

<span class="sd">    Originally, Long Short-Term Memory(LSTM) networks as a </span>
<span class="sd">    special RNN structure has proven stable and powerful for </span>
<span class="sd">    modeling long-range dependencies.</span>

<span class="sd">    The Key point of structural expansion is its memory cell </span>
<span class="sd">    which essentially acts as an accumulator of the state information. </span>
<span class="sd">    Every time observed data points are given as new information and input </span>
<span class="sd">    to LSTM’s input gate, its information will be accumulated to the cell </span>
<span class="sd">    if the input gate is activated. The past state of cell could be forgotten </span>
<span class="sd">    in this process if LSTM’s forget gate is on. Whether the latest cell output </span>
<span class="sd">    will be propagated to the final state is further controlled by the output gate.</span>

<span class="sd">    References:</span>
<span class="sd">        - Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.</span>
<span class="sd">        - Malhotra, P., Ramakrishnan, A., Anand, G., Vig, L., Agarwal, P., &amp; Shroff, G. (2016). LSTM-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148.</span>
<span class="sd">        - Zaremba, W., Sutskever, I., &amp; Vinyals, O. (2014). Recurrent neural network regularization. arXiv preprint arXiv:1409.2329.</span>

<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">lstm_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">computable_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">input_neuron_count</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
        <span class="n">observed_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">input_gate_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">forget_gate_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_gate_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">hidden_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">output_activating_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">join_io_flag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span>
    <span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Init.</span>

<span class="sd">        Args:</span>
<span class="sd">            lstm_model:                         is-a `lstm_model`.</span>
<span class="sd">            computable_loss:                    is-a `ComputableLoss`.</span>

<span class="sd">            batch_size:                         Batch size.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>

<span class="sd">            input_neuron_count:                 The number of input units.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>

<span class="sd">            hidden_neuron_count:                The number of hidden units.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>

<span class="sd">            observed_activating_function:       is-a `ActivatingFunctionInterface` in hidden layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>
<span class="sd">                                                If `None`, this value will be `TanhFunction`.</span>

<span class="sd">            input_gate_activating_function:     is-a `ActivatingFunctionInterface` in hidden layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>
<span class="sd">                                                If `None`, this value will be `LogisticFunction`.</span>

<span class="sd">            forget_gate_activating_function:    is-a `ActivatingFunctionInterface` in hidden layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>
<span class="sd">                                                If `None`, this value will be `LogisticFunction`.</span>

<span class="sd">            output_gate_activating_function:    is-a `ActivatingFunctionInterface` in hidden layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>
<span class="sd">                                                If `None`, this value will be `LogisticFunction`.</span>

<span class="sd">            hidden_activating_function:         is-a `ActivatingFunctionInterface` in hidden layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>

<span class="sd">            output_activating_function:         is-a `ActivatingFunctionInterface` in output layer.</span>
<span class="sd">                                                This parameters will be refered only when `lstm_model` is `None`.</span>
<span class="sd">                                                If `None`, this model outputs from LSTM&#39;s hidden layer in inferencing.</span>

<span class="sd">            seq_len:                            The length of sequences.</span>
<span class="sd">                                                This means refereed maxinum step `t` in feedforward.</span>

<span class="sd">            join_io_flag:                       If this value and value of `output_activating_function` is not `None`,</span>
<span class="sd">                                                This model outputs tensors combining observed data points and inferenced data</span>
<span class="sd">                                                in a series direction.</span>

<span class="sd">            learning_rate:                      Learning rate.</span>
<span class="sd">            learning_attenuate_rate:            Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>
<span class="sd">            attenuate_epoch:                    Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>
<span class="sd">                                                Additionally, in relation to regularization,</span>
<span class="sd">                                                this class constrains weight matrixes every `attenuate_epoch`.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">computable_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">computable_loss</span> <span class="o">=</span> <span class="n">MeanSquaredError</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">lstm_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lstm_model</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Init.</span>
            <span class="n">graph</span> <span class="o">=</span> <span class="n">LSTMGraph</span><span class="p">()</span>

            <span class="c1"># Activation function in LSTM.</span>
            <span class="k">if</span> <span class="n">observed_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">observed_activating_function</span> <span class="o">=</span> <span class="n">TanhFunction</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observed_activating_function</span><span class="p">,</span> <span class="n">ActivatingFunctionInterface</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">observed_activating_function</span> <span class="o">=</span> <span class="n">observed_activating_function</span>
            
            <span class="k">if</span> <span class="n">input_gate_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">input_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_gate_activating_function</span><span class="p">,</span> <span class="n">ActivatingFunctionInterface</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">input_gate_activating_function</span> <span class="o">=</span> <span class="n">input_gate_activating_function</span>
            
            <span class="k">if</span> <span class="n">forget_gate_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">forget_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">forget_gate_activating_function</span><span class="p">,</span> <span class="n">ActivatingFunctionInterface</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">forget_gate_activating_function</span> <span class="o">=</span> <span class="n">forget_gate_activating_function</span>
            
            <span class="k">if</span> <span class="n">output_gate_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">output_gate_activating_function</span> <span class="o">=</span> <span class="n">LogisticFunction</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_gate_activating_function</span><span class="p">,</span> <span class="n">ActivatingFunctionInterface</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">output_gate_activating_function</span> <span class="o">=</span> <span class="n">output_gate_activating_function</span>

            <span class="k">if</span> <span class="n">hidden_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">hidden_activating_function</span> <span class="o">=</span> <span class="n">TanhFunction</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hidden_activating_function</span><span class="p">,</span> <span class="n">ActivatingFunctionInterface</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">hidden_activating_function</span> <span class="o">=</span> <span class="n">hidden_activating_function</span>

            <span class="k">if</span> <span class="n">output_activating_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">output_activating_function</span> <span class="o">=</span> <span class="n">TanhFunction</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__output_flag</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">output_neuron_count</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">graph</span><span class="o">.</span><span class="n">output_activating_function</span> <span class="o">=</span> <span class="n">output_activating_function</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__output_flag</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">output_neuron_count</span> <span class="o">=</span> <span class="n">hidden_neuron_count</span>

            <span class="c1"># Initialization strategy.</span>
            <span class="c1"># This method initialize each weight matrices and biases in Gaussian distribution: `np.random.normal(size=hoge) * 0.01`.</span>
            <span class="n">graph</span><span class="o">.</span><span class="n">create_rnn_cells</span><span class="p">(</span>
                <span class="n">input_neuron_count</span><span class="o">=</span><span class="n">input_neuron_count</span><span class="p">,</span>
                <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
                <span class="n">output_neuron_count</span><span class="o">=</span><span class="n">output_neuron_count</span>
            <span class="p">)</span>

            <span class="n">opt_params</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">()</span>
            <span class="n">opt_params</span><span class="o">.</span><span class="n">weight_limit</span> <span class="o">=</span> <span class="mf">1e+10</span>
            <span class="n">opt_params</span><span class="o">.</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="n">lstm_model</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span>
                <span class="c1"># Delegate `graph` to `LSTMModel`.</span>
                <span class="n">graph</span><span class="o">=</span><span class="n">graph</span><span class="p">,</span>
                <span class="c1"># The number of epochs in mini-batch training.</span>
                <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                <span class="c1"># The batch size.</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="c1"># Learning rate.</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="c1"># Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>
                <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="n">learning_attenuate_rate</span><span class="p">,</span>
                <span class="c1"># Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>
                <span class="n">attenuate_epoch</span><span class="o">=</span><span class="n">attenuate_epoch</span><span class="p">,</span>
                <span class="c1"># The length of sequences.</span>
                <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
                <span class="c1"># Refereed maxinum step `t` in BPTT. If `0`, this class referes all past data in BPTT.</span>
                <span class="n">bptt_tau</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
                <span class="c1"># Size of Test data set. If this value is `0`, the validation will not be executed.</span>
                <span class="n">test_size_rate</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                <span class="c1"># Loss function.</span>
                <span class="n">computable_loss</span><span class="o">=</span><span class="n">computable_loss</span><span class="p">,</span>
                <span class="c1"># Optimizer.</span>
                <span class="n">opt_params</span><span class="o">=</span><span class="n">opt_params</span><span class="p">,</span>
                <span class="c1"># Verification function.</span>
                <span class="n">verificatable_result</span><span class="o">=</span><span class="n">VerificateFunctionApproximation</span><span class="p">(),</span>
                <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span> <span class="o">=</span> <span class="n">lstm_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__join_io_flag</span> <span class="o">=</span> <span class="n">join_io_flag</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__computable_loss</span> <span class="o">=</span> <span class="n">computable_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__loss_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__epoch_counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__learning_attenuate_rate</span> <span class="o">=</span> <span class="n">learning_attenuate_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__attenuate_epoch</span> <span class="o">=</span> <span class="n">attenuate_epoch</span>

        <span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pygan&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="o">=</span> <span class="n">logger</span>

<div class="viewcode-block" id="LSTMModel.draw"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.draw">[docs]</a>    <span class="k">def</span> <span class="nf">draw</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Draws samples from the `fake` distribution.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of samples.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">observed_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_sampler</span><span class="o">.</span><span class="n">generate</span><span class="p">()</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">arr</span></div>

<div class="viewcode-block" id="LSTMModel.inference"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.inference">[docs]</a>    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Draws samples from the `fake` distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            observed_arr:     `np.ndarray` of observed data points.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of inferenced data.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">inferenced_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__output_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_arr</span> <span class="o">=</span> <span class="n">inferenced_arr</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__join_io_flag</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">inferenced_arr</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">observed_arr</span><span class="p">,</span> <span class="n">inferenced_arr</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">get_feature_points</span><span class="p">()</span></div>

<div class="viewcode-block" id="LSTMModel.learn"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.learn">[docs]</a>    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Update this Discriminator by ascending its stochastic gradient.</span>

<span class="sd">        Args:</span>
<span class="sd">            grad_arr:   `np.ndarray` of gradients.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of delta or gradients.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">__epoch_counter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attenuate_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">__learning_attenuate_rate</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__output_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__join_io_flag</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="n">delta_arr</span><span class="p">,</span> <span class="n">grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">back_propagation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_arr</span><span class="p">,</span> <span class="n">grad_arr</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">grad_arr</span> <span class="o">=</span> <span class="n">grad_arr</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__seq_len</span><span class="p">:]</span>
                <span class="n">delta_arr</span><span class="p">,</span> <span class="n">grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">back_propagation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__inferenced_arr</span><span class="p">,</span> <span class="n">grad_arr</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">grad_arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">grad_arr</span> <span class="o">=</span> <span class="n">grad_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span>
                    <span class="n">grad_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="n">grad_arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                    <span class="o">-</span><span class="mi">1</span>
                <span class="p">))</span>
                <span class="n">grad_arr</span> <span class="o">=</span> <span class="n">grad_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">grad_arr</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">grad_arr</span> <span class="o">=</span> <span class="n">grad_arr</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">delta_arr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">grads_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">hidden_back_propagate</span><span class="p">(</span><span class="n">grad_arr</span><span class="p">)</span>
            <span class="n">grads_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">grads_list</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
            <span class="n">grads_list</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__learning_rate</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__epoch_counter</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__epoch_counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">return</span> <span class="n">delta_arr</span></div>

<div class="viewcode-block" id="LSTMModel.switch_inferencing_mode"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.switch_inferencing_mode">[docs]</a>    <span class="k">def</span> <span class="nf">switch_inferencing_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inferencing_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Set inferencing mode in relation to concrete regularizations.</span>

<span class="sd">        Args:</span>
<span class="sd">            inferencing_mode:       Inferencing mode or not.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span><span class="o">.</span><span class="n">opt_params</span><span class="o">.</span><span class="n">inferencing_mode</span> <span class="o">=</span> <span class="n">inferencing_mode</span></div>

<div class="viewcode-block" id="LSTMModel.get_lstm_model"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.get_lstm_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_lstm_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__lstm_model</span></div>
    
<div class="viewcode-block" id="LSTMModel.set_lstm_model"><a class="viewcode-back" href="../../../pygan.generativemodel.html#pygan.generativemodel.lstm_model.LSTMModel.set_lstm_model">[docs]</a>    <span class="k">def</span> <span class="nf">set_lstm_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; setter &#39;&#39;&#39;</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;This property must be read-only.&quot;</span><span class="p">)</span></div>
    
    <span class="n">lstm_model</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_lstm_model</span><span class="p">,</span> <span class="n">set_lstm_model</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">pygan  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>