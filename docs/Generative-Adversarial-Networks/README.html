

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Generative Adversarial Networks Library: pygan &#8212; pygan  documentation</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pygan package" href="pygan.html" />
    <link rel="prev" title="Welcome to pygan’s documentation!" href="index.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pygan.html" title="pygan package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pygan’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pygan  documentation</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Welcome to pygan’s documentation!</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pygan.html"
                        title="next chapter">pygan package</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="generative-adversarial-networks-library-pygan">
<span id="generative-adversarial-networks-library-pygan"></span><h1>Generative Adversarial Networks Library: pygan<a class="headerlink" href="#generative-adversarial-networks-library-pygan" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">pygan</span></code> is Python library to implement Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).</p>
<p>This library makes it possible to design the Generative models based on the Statistical machine learning problems in relation to Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN) to practice algorithm design for semi-supervised learning.</p>
<div class="section" id="installation">
<span id="installation"></span><h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Install using pip:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip install pygan
</pre></div>
</div>
<div class="section" id="source-code">
<span id="source-code"></span><h3>Source code<a class="headerlink" href="#source-code" title="Permalink to this headline">¶</a></h3>
<p>The source code is currently hosted on GitHub.</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/chimera0/accel-brain-code/tree/master/Generative-Adversarial-Networks">accel-brain-code/Generative-Adversarial-Networks</a></li>
</ul>
</div>
<div class="section" id="python-package-index-pypi">
<span id="python-package-index-pypi"></span><h3>Python package index(PyPI)<a class="headerlink" href="#python-package-index-pypi" title="Permalink to this headline">¶</a></h3>
<p>Installers for the latest released version are available at the Python package index.</p>
<ul class="simple">
<li><a class="reference external" href="https://pypi.python.org/pypi/pygan/">pygan : Python Package Index</a></li>
</ul>
</div>
<div class="section" id="dependencies">
<span id="dependencies"></span><h3>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://github.com/numpy/numpy">numpy</a>: v1.13.3 or higher.</li>
<li><a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>: v1.0.0 or higher.</li>
</ul>
</div>
</div>
<div class="section" id="documentation">
<span id="documentation"></span><h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<p>Full documentation is available on <a class="reference external" href="https://code.accel-brain.com/Generative-Adversarial-Networks/">https://code.accel-brain.com/Generative-Adversarial-Networks/</a> . This document contains information on functionally reusability, functional scalability and functional extensibility.</p>
</div>
<div class="section" id="description">
<span id="description"></span><h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">pygan</span></code> is Python library to implement Generative Adversarial Networks(GANs), <em>Conditional</em> GANs, Adversarial Auto-Encoders(AAEs), and Energy-based Generative Adversarial Network(EBGAN).</p>
<p>The Generative Adversarial Networks(GANs) (Goodfellow et al., 2014) framework establishes a
min-max adversarial game between two neural networks – a generative model, <code class="docutils literal notranslate"><span class="pre">G</span></code>, and a discriminative
model, <code class="docutils literal notranslate"><span class="pre">D</span></code>. The discriminator model, <code class="docutils literal notranslate"><span class="pre">D(x)</span></code>, is a neural network that computes the probability that
a observed data point <code class="docutils literal notranslate"><span class="pre">x</span></code> in data space is a sample from the data distribution (positive samples) that we are trying to model, rather than a sample from our generative model (negative samples). Concurrently, the generator uses a function <code class="docutils literal notranslate"><span class="pre">G(z)</span></code> that maps samples <code class="docutils literal notranslate"><span class="pre">z</span></code> from the prior <code class="docutils literal notranslate"><span class="pre">p(z)</span></code> to the data space. <code class="docutils literal notranslate"><span class="pre">G(z)</span></code> is trained to maximally confuse the discriminator into believing that samples it generates come from the data distribution. The generator is trained by leveraging the gradient of <code class="docutils literal notranslate"><span class="pre">D(x)</span></code> w.r.t. <code class="docutils literal notranslate"><span class="pre">x</span></code>, and using that to modify its parameters.</p>
<div class="section" id="structural-extension-for-conditional-gans-or-cgans">
<span id="structural-extension-for-conditional-gans-or-cgans"></span><h3>Structural extension for <em>Conditional</em> GANs (or cGANs).<a class="headerlink" href="#structural-extension-for-conditional-gans-or-cgans" title="Permalink to this headline">¶</a></h3>
<p>The <em>Conditional</em> GANs (or cGANs) is a simple extension of the basic GAN model which allows the model to condition on external information. This makes it possible to engage the learned generative model in different “modes” by providing it with different contextual information (Gauthier, J. 2014).</p>
<p>This model can be constructed by simply feeding the data, <code class="docutils literal notranslate"><span class="pre">y</span></code>, to condition on to both the generator and discriminator. In an unconditioned generative model, because the maps samples <code class="docutils literal notranslate"><span class="pre">z</span></code> from the prior <code class="docutils literal notranslate"><span class="pre">p(z)</span></code> are drawn from uniform or normal distribution, there is no control on modes of the data being generated. On the other hand, it is possible to direct the data generation process by conditioning the model on additional information (Mirza, M., &amp; Osindero, S. 2014).</p>
</div>
<div class="section" id="structural-extension-for-adversarial-auto-encoders-aaes">
<span id="structural-extension-for-adversarial-auto-encoders-aaes"></span><h3>Structural extension for Adversarial Auto-Encoders(AAEs).<a class="headerlink" href="#structural-extension-for-adversarial-auto-encoders-aaes" title="Permalink to this headline">¶</a></h3>
<p>This library also provides the Adversarial Auto-Encoders(AAEs), which is a probabilistic Auto-Encoder that uses GANs to perform variational inference by matching the aggregated posterior of the feature points in hidden layer of the Auto-Encoder with an arbitrary prior distribution(Makhzani, A., et al., 2015). Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the Adversarial Auto-Encoder learns a deep generative model that maps the imposed prior to the data distribution.</p>
</div>
<div class="section" id="structural-extension-for-energy-based-generative-adversarial-network-ebgan">
<span id="structural-extension-for-energy-based-generative-adversarial-network-ebgan"></span><h3>Structural extension for Energy-based Generative Adversarial Network(EBGAN).<a class="headerlink" href="#structural-extension-for-energy-based-generative-adversarial-network-ebgan" title="Permalink to this headline">¶</a></h3>
<p>Reusing the Auto-Encoders, this library introduces the Energy-based Generative Adversarial Network (EBGAN) model(Zhao, J., et al., 2016) which views the discriminator as an energy function that attributes low energies to the regions near the data manifold and higher energies to other regions. THe Auto-Encoders have traditionally been used to represent energy-based models. When trained with some regularization terms, the Auto-Encoders have the ability to learn an energy manifold without supervision or negative examples. This means that even when an energy-based Auto-Encoding model is trained to reconstruct a real sample, the model contributes to discovering the data manifold by itself.</p>
</div>
<div class="section" id="structural-coupling-between-aaes-and-ebgan">
<span id="structural-coupling-between-aaes-and-ebgan"></span><h3>Structural coupling between AAEs and EBGAN.<a class="headerlink" href="#structural-coupling-between-aaes-and-ebgan" title="Permalink to this headline">¶</a></h3>
<p>This library models the Energy-based Adversarial-Auto-Encoder(EBAAE) by structural coupling between AAEs and EBGAN. The learning algorithm equivalents an adversarial training of AAEs as a generator and EBGAN as a discriminator.</p>
</div>
<div class="section" id="usecase-image-generation-by-gans">
<span id="usecase-image-generation-by-gans"></span><h3>Usecase: Image Generation by GANs.<a class="headerlink" href="#usecase-image-generation-by-gans" title="Permalink to this headline">¶</a></h3>
<p>Import a Python module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygan.gan_image_generator</span> <span class="kn">import</span> <span class="n">GANImageGenerator</span>
</pre></div>
</div>
<p>Setup logger.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span><span class="p">,</span> <span class="n">StreamHandler</span><span class="p">,</span> <span class="n">NullHandler</span><span class="p">,</span> <span class="n">DEBUG</span><span class="p">,</span> <span class="n">ERROR</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;accelbrainbase&quot;</span><span class="p">)</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">StreamHandler</span><span class="p">()</span>
<span class="n">handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize <code class="docutils literal notranslate"><span class="pre">GANImageGenerator</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gan_image_generator</span> <span class="o">=</span> <span class="n">GANImageGenerator</span><span class="p">(</span>
    <span class="c1"># `list` of path to your directories.</span>
    <span class="n">dir_list</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;/path/to/your/image/files/&quot;</span><span class="p">,</span> 
    <span class="p">],</span>
    <span class="c1"># `int` of image width.</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="c1"># `int` of image height.</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
    <span class="c1"># `int` of image channel.</span>
    <span class="n">channel</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># `int` of batch size.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="c1"># `float` of learning rate.</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Call method <code class="docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gan_image_generator</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span>
    <span class="c1"># `int` of the number of training iterations.</span>
    <span class="n">iter_n</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="c1"># `int` of the number of learning of the discriminative model.</span>
    <span class="n">k_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can check logs of posterior.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">gan_image_generator</span><span class="o">.</span><span class="n">GAN</span><span class="o">.</span><span class="n">posterior_logs_arr</span><span class="p">)</span>
</pre></div>
</div>
<p>And, call method <code class="docutils literal notranslate"><span class="pre">draw</span></code>. The generated image data is stored in the variable <code class="docutils literal notranslate"><span class="pre">arr</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">arr</span> <span class="o">=</span> <span class="n">gan_image_generator</span><span class="o">.</span><span class="n">GAN</span><span class="o">.</span><span class="n">generative_model</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
<p>The shape of <code class="docutils literal notranslate"><span class="pre">arr</span></code> is …</p>
<ul class="simple">
<li>batch</li>
<li>channel</li>
<li>height</li>
<li>width</li>
</ul>
<p>For more detailed or original modeling or tuning, see <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>. This library is based on <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>.</p>
</div>
<div class="section" id="usecase-image-generation-by-ebgans">
<span id="usecase-image-generation-by-ebgans"></span><h3>Usecase: Image Generation by EBGANs.<a class="headerlink" href="#usecase-image-generation-by-ebgans" title="Permalink to this headline">¶</a></h3>
<p>Import a Python module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygan.ebgan_image_generator</span> <span class="kn">import</span> <span class="n">EBGANImageGenerator</span>
</pre></div>
</div>
<p>Setup logger.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span><span class="p">,</span> <span class="n">StreamHandler</span><span class="p">,</span> <span class="n">NullHandler</span><span class="p">,</span> <span class="n">DEBUG</span><span class="p">,</span> <span class="n">ERROR</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;accelbrainbase&quot;</span><span class="p">)</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">StreamHandler</span><span class="p">()</span>
<span class="n">handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize <code class="docutils literal notranslate"><span class="pre">EBGANImageGenerator</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ebgan_image_generator</span> <span class="o">=</span> <span class="n">EBGANImageGenerator</span><span class="p">(</span>
    <span class="c1"># `list` of path to your directories.</span>
    <span class="n">dir_list</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;/path/to/your/image/files/&quot;</span><span class="p">,</span> 
    <span class="p">],</span>
    <span class="c1"># `int` of image width.</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="c1"># `int` of image height.</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
    <span class="c1"># `int` of image channel.</span>
    <span class="n">channel</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># `int` of batch size.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="c1"># `float` of learning rate.</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Call method <code class="docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ebgan_image_generator</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span>
    <span class="c1"># `int` of the number of training iterations.</span>
    <span class="n">iter_n</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="c1"># `int` of the number of learning of the discriminative model.</span>
    <span class="n">k_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can check logs of posterior.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ebgan_image_generator</span><span class="o">.</span><span class="n">EBGAN</span><span class="o">.</span><span class="n">posterior_logs_arr</span><span class="p">)</span>
</pre></div>
</div>
<p>And, call method <code class="docutils literal notranslate"><span class="pre">draw</span></code>. The generated image data is stored in the variable <code class="docutils literal notranslate"><span class="pre">arr</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">arr</span> <span class="o">=</span> <span class="n">ebgan_image_generator</span><span class="o">.</span><span class="n">EBGAN</span><span class="o">.</span><span class="n">generative_model</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
<p>The shape of <code class="docutils literal notranslate"><span class="pre">arr</span></code> is …</p>
<ul class="simple">
<li>batch</li>
<li>channel</li>
<li>height</li>
<li>width</li>
</ul>
<p>For more detailed or original modeling or tuning, see <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>. This library is based on <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>.</p>
</div>
<div class="section" id="usecase-image-generation-by-aaes">
<span id="usecase-image-generation-by-aaes"></span><h3>Usecase: Image Generation by AAEs.<a class="headerlink" href="#usecase-image-generation-by-aaes" title="Permalink to this headline">¶</a></h3>
<p>Import a Python module.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pygan.ebaae_image_generator</span> <span class="kn">import</span> <span class="n">EBAAEImageGenerator</span>
</pre></div>
</div>
<p>Setup a logger.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span><span class="p">,</span> <span class="n">StreamHandler</span><span class="p">,</span> <span class="n">NullHandler</span><span class="p">,</span> <span class="n">DEBUG</span><span class="p">,</span> <span class="n">ERROR</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;accelbrainbase&quot;</span><span class="p">)</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">StreamHandler</span><span class="p">()</span>
<span class="n">handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<p>Initialize <code class="docutils literal notranslate"><span class="pre">EBAAEImageGenerator</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ebaae_image_generator</span> <span class="o">=</span> <span class="n">EBAAEImageGenerator</span><span class="p">(</span>
    <span class="c1"># `list` of path to your directories.</span>
    <span class="n">dir_list</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;/path/to/your/image/files/&quot;</span><span class="p">,</span> 
    <span class="p">],</span>
    <span class="c1"># `int` of image width.</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="c1"># `int` of image height.</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">96</span><span class="p">,</span>
    <span class="c1"># `int` of image channel.</span>
    <span class="n">channel</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="c1"># `int` of batch size.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
    <span class="c1"># `float` of learning rate.</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
    <span class="c1"># `int` of width of image drawn from normal distribution, p(z).</span>
    <span class="n">normal_height</span><span class="o">=</span><span class="mi">128</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span>
    <span class="c1"># `int` of height of image drawn from normal distribution, p(z).</span>
    <span class="n">normal_width</span><span class="o">=</span><span class="mi">96</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Call method <code class="docutils literal notranslate"><span class="pre">learn</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ebaae_image_generator</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span>
    <span class="c1"># `int` of the number of training iterations.</span>
    <span class="n">iter_n</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
    <span class="c1"># `int` of the number of learning of the discriminative model.</span>
    <span class="n">k_step</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can check logs of posterior.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">ebaae_image_generator</span><span class="o">.</span><span class="n">EBAAE</span><span class="o">.</span><span class="n">posterior_logs_arr</span><span class="p">)</span>
</pre></div>
</div>
<p>And, call method <code class="docutils literal notranslate"><span class="pre">draw</span></code>. The generated image data is stored in the variable <code class="docutils literal notranslate"><span class="pre">decoded_arr</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">arr_tuple</span> <span class="o">=</span> <span class="n">ebaae_image_generator</span><span class="o">.</span><span class="n">EBAAE</span><span class="o">.</span><span class="n">generative_model</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
<span class="n">feature_points_arr</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">,</span> <span class="n">decoded_arr</span> <span class="o">=</span> <span class="n">arr_tuple</span>
</pre></div>
</div>
<p>The shape of <code class="docutils literal notranslate"><span class="pre">decoded_arr</span></code> is …</p>
<ul class="simple">
<li>batch</li>
<li>channel</li>
<li>height</li>
<li>width</li>
</ul>
<p>For more detailed or original modeling or tuning, see <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>. This library is based on <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>.</p>
</div>
</div>
<div class="section" id="references">
<span id="references"></span><h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Fang, W., Zhang, F., Sheng, V. S., &amp; Ding, Y. (2018). A method for improving CNN-based image recognition using DCGAN. Comput. Mater. Contin, 57, 167-178.</li>
<li>Gauthier, J. (2014). Conditional generative adversarial nets for convolutional face generation. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester, 2014(5), 2.</li>
<li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</li>
<li>Long, J., Shelhamer, E., &amp; Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3431-3440).</li>
<li>Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., &amp; Frey, B. (2015). Adversarial autoencoders. arXiv preprint arXiv:1511.05644.</li>
<li>Mirza, M., &amp; Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784.</li>
<li>Mogren, O. (2016). C-RNN-GAN: Continuous recurrent neural networks with adversarial training. arXiv preprint arXiv:1611.09904.</li>
<li>Rifai, S., Vincent, P., Muller, X., Glorot, X., &amp; Bengio, Y. (2011, June). Contractive auto-encoders: Explicit invariance during feature extraction. In Proceedings of the 28th International Conference on International Conference on Machine Learning (pp. 833-840). Omnipress.</li>
<li>Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio, Y., Dauphin, Y., &amp; Glorot, X. (2011, September). Higher order contractive auto-encoder. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases (pp. 645-660). Springer, Berlin, Heidelberg.</li>
<li>Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., &amp; Chen, X. (2016). Improved techniques for training gans. In Advances in neural information processing systems (pp. 2234-2242).</li>
<li>Yang, L. C., Chou, S. Y., &amp; Yang, Y. H. (2017). MidiNet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847.</li>
<li>Zhao, J., Mathieu, M., &amp; LeCun, Y. (2016). Energy-based generative adversarial network. arXiv preprint arXiv:1609.03126.</li>
<li>Warde-Farley, D., &amp; Bengio, Y. (2016). Improving generative adversarial networks with denoising feature matching.</li>
</ul>
<div class="section" id="related-poc">
<span id="related-poc"></span><h3>Related PoC<a class="headerlink" href="#related-poc" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/">深層強化学習のベイズ主義的な情報探索に駆動された自然言語処理の意味論</a> (Japanese)<ul>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/regularisierungsproblem-und-gan/">正則化問題における敵対的生成ネットワーク(GANs)と敵対的自己符号化器(AAEs)のネットワーク構造</a></li>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/hierarchical-latent-variable-model-as-media-and-semi-supervised-learning-of-ladder-network-as-a-form/">階層的潜在変数モデルをメディアとしたラダーネットワークの半教師あり学習形式、ノイズ除去型自己符号化器の機能</a></li>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/lyaponov-stability-optimization-in-gan-and-auto-encoder-in-energy-based-models/">エネルギーベースモデルとしての敵対的生成ネットワーク(GAN)と自己符号化器におけるリアプノフ安定</a></li>
</ul>
</li>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/">「人工の理想」を背景とした「万物照応」のデータモデリング</a> (Japanese)<ul>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/sozialstruktur-von-random-walk-und-semantik-der-dow-theorie/">ランダムウォークの社会構造とダウ理論の意味論、再帰的ニューラルネットワークの価格変動モデルから敵対的生成ネットワーク（GAN）へ</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="author">
<span id="author"></span><h2>Author<a class="headerlink" href="#author" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>accel-brain</li>
</ul>
</div>
<div class="section" id="author-uri">
<span id="author-uri"></span><h2>Author URI<a class="headerlink" href="#author-uri" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>https://accel-brain.co.jp/</li>
<li>https://accel-brain.com/</li>
</ul>
</div>
<div class="section" id="license">
<span id="license"></span><h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>GNU General Public License v2.0</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pygan.html" title="pygan package"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pygan’s documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pygan  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>