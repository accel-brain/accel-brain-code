

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pysummarization.vectorizablesentence package &#8212; pysummarization  documentation</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pysummarization.vectorizabletoken package" href="pysummarization.vectorizabletoken.html" />
    <link rel="prev" title="pysummarization.tokenizabledoc package" href="pysummarization.tokenizabledoc.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pysummarization.vectorizabletoken.html" title="pysummarization.vectorizabletoken package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="pysummarization.tokenizabledoc.html" title="pysummarization.tokenizabledoc package"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pysummarization.html" accesskey="U">pysummarization package</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="pysummarization.tokenizabledoc.html"
                        title="previous chapter">pysummarization.tokenizabledoc package</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pysummarization.vectorizabletoken.html"
                        title="next chapter">pysummarization.vectorizabletoken package</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pysummarization-vectorizablesentence-package">
<h1>pysummarization.vectorizablesentence package<a class="headerlink" href="#pysummarization-vectorizablesentence-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pysummarization.vectorizablesentence.encoder_decoder">
<span id="pysummarization-vectorizablesentence-encoder-decoder-module"></span><h2>pysummarization.vectorizablesentence.encoder_decoder module<a class="headerlink" href="#module-pysummarization.vectorizablesentence.encoder_decoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder">
<em class="property">class </em><code class="descclassname">pysummarization.vectorizablesentence.encoder_decoder.</code><code class="descname">EncoderDecoder</code><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/encoder_decoder.html#EncoderDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pysummarization.html#pysummarization.vectorizable_sentence.VectorizableSentence" title="pysummarization.vectorizable_sentence.VectorizableSentence"><code class="xref py py-class docutils literal notranslate"><span class="pre">pysummarization.vectorizable_sentence.VectorizableSentence</span></code></a></p>
<p>Vectorize sentences by Encoder/Decoder based on LSTM.</p>
<p>This library provides Encoder/Decoder based on LSTM,
which is a reconstruction model and makes it possible to
extract series features embedded in deeper layers.
The LSTM encoder learns a fixed length vector of time-series
observed data points and the LSTM decoder uses this representation
to reconstruct the time-series using the current hidden state
and the value inferenced at the previous time-step.</p>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_sine_wave_prediction_by_LSTM_encoder_decoder.ipynb">https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_sine_wave_prediction_by_LSTM_encoder_decoder.ipynb</a></li>
<li><a class="reference external" href="https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_anomaly_detection_by_enc_dec_ad.ipynb">https://github.com/chimera0/accel-brain-code/blob/master/Deep-Learning-by-means-of-Design-Pattern/demo/demo_anomaly_detection_by_enc_dec_ad.ipynb</a></li>
<li>Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.</li>
<li>Malhotra, P., Ramakrishnan, A., Anand, G., Vig, L., Agarwal, P., &amp; Shroff, G. (2016). LSTM-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148.</li>
</ul>
<dl class="attribute">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.controller">
<code class="descname">controller</code><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.get_controller">
<code class="descname">get_controller</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/encoder_decoder.html#EncoderDecoder.get_controller"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.get_controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>sentence_list</em>, <em>token_master_list</em>, <em>hidden_neuron_count=200</em>, <em>epochs=100</em>, <em>batch_size=100</em>, <em>learning_rate=1e-05</em>, <em>learning_attenuate_rate=0.1</em>, <em>attenuate_epoch=50</em>, <em>weight_limit=0.5</em>, <em>dropout_rate=0.5</em>, <em>test_size_rate=0.3</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/encoder_decoder.html#EncoderDecoder.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Init.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sentence_list</strong> – The list of tokenized sentences.
[[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …]]</li>
<li><strong>token_master_list</strong> – Unique <cite>list</cite> of tokens.</li>
<li><strong>hidden_neuron_count</strong> – The number of units in hidden layer.</li>
<li><strong>epochs</strong> – Epochs of Mini-batch.</li>
<li><strong>batch_size</strong> – Batch size of Mini-batch.</li>
<li><strong>learning_rate</strong> – Learning rate.</li>
<li><strong>learning_attenuate_rate</strong> – Attenuate the <cite>learning_rate</cite> by a factor of this value every <cite>attenuate_epoch</cite>.</li>
<li><strong>attenuate_epoch</strong> – Attenuate the <cite>learning_rate</cite> by a factor of <cite>learning_attenuate_rate</cite> every <cite>attenuate_epoch</cite>.
Additionally, in relation to regularization,
this class constrains weight matrixes every <cite>attenuate_epoch</cite>.</li>
<li><strong>weight_limit</strong> – Regularization for weights matrix
to repeat multiplying the weights matrix and <cite>0.9</cite>
until $sum_{j=0}^{n}w_{ji}^2 &lt; weight_limit$.</li>
<li><strong>dropout_rate</strong> – The probability of dropout.</li>
<li><strong>test_size_rate</strong> – Size of Test data set. If this value is <cite>0</cite>, the</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.set_readonly">
<code class="descname">set_readonly</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/encoder_decoder.html#EncoderDecoder.set_readonly"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.set_readonly" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.vectorize">
<code class="descname">vectorize</code><span class="sig-paren">(</span><em>sentence_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/encoder_decoder.html#EncoderDecoder.vectorize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.encoder_decoder.EncoderDecoder.vectorize" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_list</strong> – The list of tokenized sentences.
[[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …]]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of tokens.
[vector of token, vector of token, vector of token]</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pysummarization.vectorizablesentence.lstm_rtrbm">
<span id="pysummarization-vectorizablesentence-lstm-rtrbm-module"></span><h2>pysummarization.vectorizablesentence.lstm_rtrbm module<a class="headerlink" href="#module-pysummarization.vectorizablesentence.lstm_rtrbm" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM">
<em class="property">class </em><code class="descclassname">pysummarization.vectorizablesentence.lstm_rtrbm.</code><code class="descname">LSTMRTRBM</code><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/lstm_rtrbm.html#LSTMRTRBM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pysummarization.html#pysummarization.vectorizable_sentence.VectorizableSentence" title="pysummarization.vectorizable_sentence.VectorizableSentence"><code class="xref py py-class docutils literal notranslate"><span class="pre">pysummarization.vectorizable_sentence.VectorizableSentence</span></code></a></p>
<p>Vectorize sentences by LSTM-RTRBM.</p>
<p>LSTM-RTRBM model integrates the ability of LSTM in memorizing
and retrieving useful history information, together with the
advantage of RBM in high dimensional data
modelling(Lyu, Q., Wu, Z., Zhu, J., &amp; Meng, H. 2015, June).
Like RTRBM, LSTM-RTRBM also has the recurrent hidden units.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Boulanger-Lewandowski, N., Bengio, Y., &amp; Vincent, P. (2012). Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription. arXiv preprint arXiv:1206.6392.</li>
<li>Lyu, Q., Wu, Z., Zhu, J., &amp; Meng, H. (2015, June). Modelling High-Dimensional Sequences with LSTM-RTRBM: Application to Polyphonic Music Generation. In IJCAI (pp. 4138-4139).</li>
<li>Lyu, Q., Wu, Z., &amp; Zhu, J. (2015, October). Polyphonic music modelling with LSTM-RTRBM. In Proceedings of the 23rd ACM international conference on Multimedia (pp. 991-994). ACM.</li>
<li>Sutskever, I., Hinton, G. E., &amp; Taylor, G. W. (2009). The recurrent temporal restricted boltzmann machine. In Advances in Neural Information Processing Systems (pp. 1601-1608).</li>
</ul>
<dl class="method">
<dt id="pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>sentence_list</em>, <em>token_master_list</em>, <em>hidden_neuron_count=1000</em>, <em>training_count=1</em>, <em>batch_size=100</em>, <em>learning_rate=0.001</em>, <em>seq_len=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/lstm_rtrbm.html#LSTMRTRBM.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Init.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sentence_list</strong> – The <cite>list</cite> of sentences.</li>
<li><strong>token_master_list</strong> – Unique <cite>list</cite> of tokens.</li>
<li><strong>hidden_neuron_count</strong> – The number of units in hidden layer.</li>
<li><strong>training_count</strong> – The number of training.</li>
<li><strong>bath_size</strong> – Batch size of Mini-batch.</li>
<li><strong>learning_rate</strong> – Learning rate.</li>
<li><strong>seq_len</strong> – The length of one sequence.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM.vectorize">
<code class="descname">vectorize</code><span class="sig-paren">(</span><em>sentence_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/vectorizablesentence/lstm_rtrbm.html#LSTMRTRBM.vectorize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.vectorizablesentence.lstm_rtrbm.LSTMRTRBM.vectorize" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>sentence_list</strong> – The list of tokenized sentences.
[[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …],
[<cite>token</cite>, <cite>token</cite>, <cite>token</cite>, …]]</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of tokens.
[vector of token, vector of token, vector of token]</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pysummarization.vectorizablesentence">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pysummarization.vectorizablesentence" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pysummarization.vectorizabletoken.html" title="pysummarization.vectorizabletoken package"
             >next</a> |</li>
        <li class="right" >
          <a href="pysummarization.tokenizabledoc.html" title="pysummarization.tokenizabledoc package"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pysummarization.html" >pysummarization package</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>