# 「AIの民主化」時代の企業内研究開発: 深層学習の「実学」としての機能分析

<div align="center"><a href="https://www.amazon.co.jp/dp/B08PV4ZQG5/ref=sr_1_1?dchild=1&qid=1607343553&s=digital-text&sr=1-1&text=%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BEAccel+Brain" target="_blank"><img src="https://storage.googleapis.com/accel-brain-code/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/book_cover.jpg" width="160px" /></a>
  <p>『<a href="https://www.amazon.co.jp/dp/B08PV4ZQG5/" target="_blank">「AIの民主化」時代の企業内研究開発: 深層学習の「実学」としての機能分析</a>』(Japanese)</p></div>


## 目次と対応するノートブック

### 1. 序論

-   問題設定：「AIブームの終焉」としての「民主化」
    -   問題解決策：「AIの民主化」時代の実学
    -   問題解決策：この本

### 2. 企業内研究開発の方法としての「機能分析」

-   問題設定：深層学習の企業内研究開発は「科学」なのか
    -   問題解決策：「科学」と「芸術」の区別
-   派生問題：深層学習の企業内研究開発は「芸術」なのか
    -   問題解決策：「複合的なシステム」としての深層学習
    -   問題解決策：「複合的なシステム」としての企業内研究開発
-  問題再設定：企業内研究開発は如何にして可能になるのか
    -   問題解決策：機能分析
-   派生問題：無限後退
    -   問題解決策：機能分析の機能分析

### 3. 深層学習小史：サイバネティクス、コネクショニズム、システム理論

-   派生問題：「抽象化」は如何にして可能になるのか
    -   問題解決策：オブジェクト指向分析
    -   問題解決策：サイバネティクス
-   派生問題：創発的な秩序は如何にして可能になるのか
    -   問題解決策：コネクショニズム
-   派生問題：「深層学習」と「脳」の差異
    -   問題解決策：計算機資源の発展
-   派生問題：教師データの人的コスト
-   問題再設定：教師データの人的コスト
    -   問題解決策：セカンドオーダー・サイバネティクスの「固有値」
    -   問題解決策：自己言及的なシステム
-   問題再設定：自律的な深層学習は如何にして可能になるのか
    -   問題解決策：強化学習問題の枠組み
    -   機能的等価物：表現学習問題の枠組み
    -   機能的等価物：半教師あり学習問題の枠組み
    -   機能的等価物：自己教師あり学習問題の枠組み
    -   問題解決策：「AI」の固有値

### 4. ニューラルネットワーク最適化問題

-   問題設定：誤差関数の最小化問題としての最適化問題（ノートブック：[demo_4-1.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_4-1.ipynb)）
    -   問題解決策：偏微分
    -   問題解決策：勾配降下法
    -   問題解決策：連鎖律の原理
-   問題再設定：回帰問題（ノートブック：[demo_4-2.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_4-2.ipynb)）
    -   問題解決策：線形回帰モデル
    -   [問題解決策：平均二乗誤差関数
-   派生問題：複合性の表現力（ノートブック：[demo_4-3.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_4-3.ipynb)）
    -   問題解決策：活性化関数
    -   問題解決策：隠れ層
    -   問題解決策：多様体仮説
-   派生問題：計算コストと勾配消失
-   問題再設定：ニューラルネットワーク最適化問題（ノートブック：[demo_4-4.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_4-4.ipynb)）
    -   問題解決策：確率的勾配降下法
    -   問題解決策：モメンタム
    -   機能的等価物：NAG
    -   機能的等価物：AdaGrad
    -   機能的等価物：RMSProp
    -   機能的等価物：Adam
    -   機能的等価物：Nadam
-   派生問題：パラメタの初期化戦略
-   問題設定：分類問題（ノートブック：[demo_4-5.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_4-5.ipynb)）
    -   問題解決策：エントロピー
    -   問題解決策：KLダイバージェンス
    -   機能的等価物：交差エントロピー
-   コラム（１）：「熱」とは何か
    -   問題解決策：分子運動論
    -   問題解決策：「マクロ」と「ミクロ」の区別
    -   問題解決策：ボルツマン定数
    -   問題解決策：抽象としての平衡
    -   問題解決策：カノニカル・アンサンブル
    -   問題解決策：シャノンエントロピーとの接続

### 5. ベイズ主義

-   問題設定：大統領選の「賭けサイト」の予測は、如何に失敗したのか
    -   問題解決策：「ベイズの定理」
    -   問題解決策：「オッズ」のベイズ更新
    -   問題解決策：理由不十分の原則
    -   問題解決策：逐次合理性
-   派生問題：第三項排除律
-   問題設定：「感染者問題」
    -   問題解決策：ベイズの定理
-   派生問題：「ベイズの定理」からの違反
-   コラム（２）：ベイズ主義の神学的な理念について
    -   問題解決策：神学から確率論への展開
    -   問題解決策：＜自責＞と＜他責＞の区別
-   問題設定：ハイパーパラメタの決定は如何にして可能になるのか
    -   問題解決策：「訓練誤差」と「汎化誤差」の区別
-   問題再設定：「過少適合」と「過剰適合」
    -   問題解決策：許容力
    -   問題解決策：正則化項
    -   問題解決策：交差検証
-   問題再設定：汎化問題の枠組み
    -   問題解決策：形式としての推定量
    -   問題解決策：最尤推定
    -   機能的等価物：ベイズ統計
    -   問題解決策：最大事後確率推定
-   コラム（３）：旧い統計学の規範化
    -   問題解決策：統計的仮説検定の有意水準
    -   問題解決策：無作為標本抽出
    -   問題解決策：ビッグデータの分析技術
-   派生問題：ビッグデータにおける限定合理性
    -   問題解決策：「情報的事前分布」と「非情報的事前分布」の区別

### 6. アーキテクチャ設計

-   問題設定：機械学習ライブラリの機能的な拡張性
    -   問題解決策：accel-brain-base
-   問題設定：深層アーキテクチャの積層構造は如何にして可能になったのか（ノートブック：[demo_6-2.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-2.ipynb)）
-   問題再設定：統計的機械学習問題の枠組み
    -   問題解決策：グラフとノードの区別
    -   問題解決策：ボルツマンマシン
    -   問題解決策：ボルツマンマシンの学習方程式
    -   問題解決策：「隠れ変数あり」のボルツマンマシンの学習方程式
    -   問題解決策：KLダイバージェンス
-   派生問題：組み合わせ爆発
    -   問題解決策：ギブスサンプラー
    -   機能的等価物：コントラスティブ・ダイバージェンス法
    -   問題解決策：制限ボルツマンマシン
    -   問題解決策：深層ボルツマンマシン
    -   問題解決策：平均場近似
-   派生問題：「事前学習」は如何にして可能になるのか
    -   問題解決策：「層ごとの貪欲な教師なし事前学習」の棄却
    -   問題解決策：教師なし事前学習の正則化機能
-   派生問題：情報保持と情報破棄の両立
-   問題再設定：教師なし学習の再導入は如何にして可能になるのか（ノートブック：[demo_6-4.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-4.ipynb)）
    -   問題解決策：階層的潜在変数モデル
    -   機能的等価物：積層自己符号化器
    -   機能的等価物：ラダーネットワーク
    -   問題解決策：ノイズ除去型自己符号化器
    -   問題解決策：ラダーネットワークの学習アルゴリズム
-   派生問題：ラダーネットワークとの構造的な結合点
-   派生問題：半教師あり学習における表現学習は如何にして可能になるのか
    -   問題解決策：ベイズ主義
    -   問題解決策：＜教師なし学習＞概念の再記述
-   問題設定：「深層学習のコモディティ化」以降の深層学習（ノートブック：[demo_6-3.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-3.ipynb)）
-   問題再設定：深層学習の計算コスト削減は如何にして可能になるのか
    -   問題解決策：標準的な畳み込み層
    -   機能的等価物：深さ志向の分離可能な畳み込み層
    -   問題解決策：アルゴリズムの機能的な比較
    -   問題解決策：横幅の乗数
    -   問題解決策：解像度の乗数
-   派生問題：計算コスト削減の代償
-   問題再設定：情報損失
-   問題再設定：次元削減問題の枠組み
    -   問題解決策：反転残差構造
    -   問題解決策：深層残差学習
    -   機能的等価物：ボトルネック残差ブロック
    -   問題解決策：許容力と表現力の区別
-   問題設定：過剰適合
    -   問題解決策：ドロップアウト
-   問題再設定：正則化問題
-   問題再設定：統計的機械学習問題の枠組み（ノートブック：[demo_6-5.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-5.ipynb)）
    -   問題解決策：敵対的生成ネットワーク
-   問題設定：GANの分類問題
-   問題再設定：GANの多クラス分類問題
-   問題再設定：GANのクラス確率最適化問題
    -   [問題解決策：シャノンエントロピーの情報理論
-   [問題再設定：半教師あり学習問題の枠組み
    -   問題解決策：半教師ありCatGAN
    -   機能的等価物：半教師あり敵対的自己符号化器
    -   機能的等価物：エネルギーベースの敵対的生成ネットワーク
-   派生問題：自己符号化器の恒等関数化
    -   問題解決策：反発正則化付き自己符号化器
    -   機能的等価物：縮小自己符号化器
    -   機能的等価物：ノイズ除去型自己符号化器
-   派生問題：転移学習問題の枠組み（ノートブック：[demo_6-6.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-6.ipynb)）
    -   問題解決策：Nショット学習
    -   問題解決策：ドメイン適応
    -   問題解決策：概念漂流
-   派生問題：転移学習のパラドックス
    -   問題解決策：教師あり事前学習と教師なし事前学習の区別
    -   問題解決策：深層再構成分類ネットワーク
    -   問題解決策：＜教師あり学習＞と＜教師なし学習＞の区別
-   派生問題：「教師あり学習」の終焉
-   問題再設定：「教師あり学習」の終焉後のドメイン適応（ノートブック：[demo_6-7.ipynb](https://github.com/accel-brain/accel-brain-code/blob/master/Accel-Brain-Books/In-house_R_and_D_in_the_era_of_democratization_of_AI/Functional_analysis_as_a_practical_practice_of_deep_learning/demo_6-7.ipynb)）
    -   問題解決策：PixelDA
    -   機能的等価物：CrDoCo
    -   機能的等価物：「自己教師あり」ドメイン適応

### 7. おわりに

-   問題再設定：「AI」の企業内研究開発は如何にして可能になるのか
    -   問題解決策：「AI」の開発プロセス
-   派生問題：要求定義の無限後退
    -   問題解決策：「進歩」なき研究開発
    -   問題解決策：「設計」としての「区別」
    -   問題解決策：機能主義的なシステム理論
- 用語解説
- 参考文献

