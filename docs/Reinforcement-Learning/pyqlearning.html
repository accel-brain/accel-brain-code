

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pyqlearning package &#8212; pyqlearning  documentation</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pyqlearning.annealingmodel package" href="pyqlearning.annealingmodel.html" />
    <link rel="prev" title="Reinforcement Learning Library: pyqlearning" href="README.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pyqlearning.annealingmodel.html" title="pyqlearning.annealingmodel package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="README.html" title="Reinforcement Learning Library: pyqlearning"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pyqlearning  documentation</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="README.html"
                        title="previous chapter">Reinforcement Learning Library: pyqlearning</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pyqlearning.annealingmodel.html"
                        title="next chapter">pyqlearning.annealingmodel package</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pyqlearning-package">
<h1>pyqlearning package<a class="headerlink" href="#pyqlearning-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="pyqlearning.annealingmodel.html">pyqlearning.annealingmodel package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#subpackages">Subpackages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="pyqlearning.annealingmodel.costfunctionable.html">pyqlearning.annealingmodel.costfunctionable package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.costfunctionable.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.costfunctionable.html#module-pyqlearning.annealingmodel.costfunctionable.boltzmann_q_learning_cost">pyqlearning.annealingmodel.costfunctionable.boltzmann_q_learning_cost module</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.costfunctionable.html#module-pyqlearning.annealingmodel.costfunctionable.greedy_q_learning_cost">pyqlearning.annealingmodel.costfunctionable.greedy_q_learning_cost module</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.costfunctionable.html#module-pyqlearning.annealingmodel.costfunctionable">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyqlearning.annealingmodel.distancecomputable.html">pyqlearning.annealingmodel.distancecomputable package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.distancecomputable.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.distancecomputable.html#module-pyqlearning.annealingmodel.distancecomputable.cost_as_distance">pyqlearning.annealingmodel.distancecomputable.cost_as_distance module</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.distancecomputable.html#module-pyqlearning.annealingmodel.distancecomputable.euclidean">pyqlearning.annealingmodel.distancecomputable.euclidean module</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.distancecomputable.html#module-pyqlearning.annealingmodel.distancecomputable">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="pyqlearning.annealingmodel.simulatedannealing.html">pyqlearning.annealingmodel.simulatedannealing package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.simulatedannealing.html#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.simulatedannealing.html#module-pyqlearning.annealingmodel.simulatedannealing.adaptive_simulated_annealing">pyqlearning.annealingmodel.simulatedannealing.adaptive_simulated_annealing module</a></li>
<li class="toctree-l4"><a class="reference internal" href="pyqlearning.annealingmodel.simulatedannealing.html#module-pyqlearning.annealingmodel.simulatedannealing">Module contents</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#module-pyqlearning.annealingmodel.cost_functionable">pyqlearning.annealingmodel.cost_functionable module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#module-pyqlearning.annealingmodel.distance_computable">pyqlearning.annealingmodel.distance_computable module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#module-pyqlearning.annealingmodel.quantum_monte_carlo">pyqlearning.annealingmodel.quantum_monte_carlo module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#module-pyqlearning.annealingmodel.simulated_annealing">pyqlearning.annealingmodel.simulated_annealing module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.annealingmodel.html#module-pyqlearning.annealingmodel">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="pyqlearning.qlearning.html">pyqlearning.qlearning package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.qlearning.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.qlearning.html#module-pyqlearning.qlearning.boltzmann_q_learning">pyqlearning.qlearning.boltzmann_q_learning module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.qlearning.html#module-pyqlearning.qlearning.greedy_q_learning">pyqlearning.qlearning.greedy_q_learning module</a></li>
<li class="toctree-l2"><a class="reference internal" href="pyqlearning.qlearning.html#module-pyqlearning.qlearning">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pyqlearning.annealing_model">
<span id="pyqlearning-annealing-model-module"></span><h2>pyqlearning.annealing_model module<a class="headerlink" href="#module-pyqlearning.annealing_model" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pyqlearning.annealing_model.AnnealingModel">
<em class="property">class </em><code class="descclassname">pyqlearning.annealing_model.</code><code class="descname">AnnealingModel</code><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract class of Annealing.</p>
<p>There are many hyperparameters that we have to set before
the actual searching and learning process begins.
Each parameter should be decided in relation to Deep/Reinforcement Learning theory
and it cause side effects in training model. Because of this complexity of hyperparameters,
so-called the hyperparameter tuning must become a burden of Data scientists
and R &amp; D engineers from the perspective of not only a theoretical point of view
but also implementation level.</p>
<p>This issue can be considered as Combinatorial optimization problem which is
an optimization problem, where an optimal solution has to be identified from
a finite set of solutions. The solutions are normally discrete or can be converted
into discrete. This is an important topic studied in operations research such as
software engineering, artificial intelligence(AI), and machine learning. For instance,
travelling sales man problem is one of the popular combinatorial optimization problem.</p>
<p>In this problem setting, this library provides an Annealing Model to search optimal
combination of hyperparameters. For instance, Simulated Annealing is a probabilistic
single solution based search method inspired by the annealing process in metallurgy.
Annealing is a physical process referred to as tempering certain alloys of metal,
glass, or crystal by heating above its melting point, holding its temperature,
and then cooling it very slowly until it solidifies into a perfect crystalline structure.
The simulation of this process is known as simulated annealing.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Bektas, T. (2006). The multiple traveling salesman problem: an overview of formulations and solution procedures. Omega, 34(3), 209-219.</li>
<li>Bertsimas, D., &amp; Tsitsiklis, J. (1993). Simulated annealing. Statistical science, 8(1), 10-15.</li>
<li>Das, A., &amp; Chakrabarti, B. K. (Eds.). (2005). Quantum annealing and related optimization methods (Vol. 679). Springer Science &amp; Business Media.</li>
<li>Du, K. L., &amp; Swamy, M. N. S. (2016). Search and optimization by metaheuristics. New York City: Springer.</li>
<li>Edwards, S. F., &amp; Anderson, P. W. (1975). Theory of spin glasses. Journal of Physics F: Metal Physics, 5(5), 965.</li>
<li>Facchi, P., &amp; Pascazio, S. (2008). Quantum Zeno dynamics: mathematical and physical aspects. Journal of Physics A: Mathematical and Theoretical, 41(49), 493001.</li>
<li>Heim, B., Rønnow, T. F., Isakov, S. V., &amp; Troyer, M. (2015). Quantum versus classical annealing of Ising spin glasses. Science, 348(6231), 215-217.</li>
<li>Heisenberg, W. (1925) Über quantentheoretische Umdeutung kinematischer und mechanischer Beziehungen. Z. Phys. 33, pp.879—893.</li>
<li>Heisenberg, W. (1927). Über den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik. Zeitschrift fur Physik, 43, 172-198.</li>
<li>Heisenberg, W. (1984). The development of quantum mechanics. In Scientific Review Papers, Talks, and Books -Wissenschaftliche Übersichtsartikel, Vorträge und Bücher (pp. 226-237). Springer Berlin Heidelberg. Hilgevoord, Jan and Uffink, Jos, “The Uncertainty Principle”, The Stanford Encyclopedia of Philosophy (Winter 2016 Edition), Edward N. Zalta (ed.), URL = ＜https://plato.stanford.edu/archives/win2016/entries/qt-uncertainty/＞.</li>
<li>Jarzynski, C. (1997). Nonequilibrium equality for free energy differences. Physical Review Letters, 78(14), 2690.</li>
<li>Messiah, A. (1966). Quantum mechanics. 2 (1966). North-Holland Publishing Company.</li>
<li>Mezard, M., &amp; Montanari, A. (2009). Information, physics, and computation. Oxford University Press.</li>
<li>Nallusamy, R., Duraiswamy, K., Dhanalaksmi, R., &amp; Parthiban, P. (2009). Optimization of non-linear multiple traveling salesman problem using k-means clustering, shrink wrap algorithm and meta-heuristics. International Journal of Nonlinear Science, 8(4), 480-487.</li>
<li>Schrödinger, E. (1926). Quantisierung als eigenwertproblem. Annalen der physik, 385(13), S.437-490.</li>
<li>Somma, R. D., Batista, C. D., &amp; Ortiz, G. (2007). Quantum approach to classical statistical mechanics. Physical review letters, 99(3), 030603.</li>
<li>鈴木正. (2008). 「組み合わせ最適化問題と量子アニーリング: 量子断熱発展の理論と性能評価」.,『物性研究』, 90(4): pp598-676. 参照箇所はpp619-624.</li>
<li>西森秀稔、大関真之(2018) 『量子アニーリングの基礎』須藤 彰三、岡 真 監修、共立出版、参照箇所はpp9-46.</li>
</ul>
<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.accepted_pos">
<code class="descname">accepted_pos</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.accepted_pos" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.annealing">
<code class="descname">annealing</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.annealing"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.annealing" title="Permalink to this definition">¶</a></dt>
<dd><p>Annealing.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.computed_cost_arr">
<code class="descname">computed_cost_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.computed_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.current_cost_arr">
<code class="descname">current_cost_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.current_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.current_dist_arr">
<code class="descname">current_dist_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.current_dist_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.fit_dist_mat">
<code class="descname">fit_dist_mat</code><span class="sig-paren">(</span><em>dist_mat_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.fit_dist_mat"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.fit_dist_mat" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit ovserved data points.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>dist_mat_arr</strong> – fitted data points.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_accepted_pos">
<code class="descname">get_accepted_pos</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_accepted_pos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_accepted_pos" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_computed_cost_arr">
<code class="descname">get_computed_cost_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_computed_cost_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_computed_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_current_cost_arr">
<code class="descname">get_current_cost_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_current_cost_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_current_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_current_dist_arr">
<code class="descname">get_current_dist_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_current_dist_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_current_dist_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_predicted_log_arr">
<code class="descname">get_predicted_log_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_predicted_log_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_predicted_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_predicted_log_list">
<code class="descname">get_predicted_log_list</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_predicted_log_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_predicted_log_list" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_stocked_predicted_arr">
<code class="descname">get_stocked_predicted_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_stocked_predicted_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_stocked_predicted_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_var_arr">
<code class="descname">get_var_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_var_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_var_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_var_log_arr">
<code class="descname">get_var_log_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_var_log_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_var_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.get_x">
<code class="descname">get_x</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.get_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.get_x" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.predicted_log_arr">
<code class="descname">predicted_log_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.predicted_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.predicted_log_list">
<code class="descname">predicted_log_list</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.predicted_log_list" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_accepted_pos">
<code class="descname">set_accepted_pos</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_accepted_pos"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_accepted_pos" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_computed_cost_arr">
<code class="descname">set_computed_cost_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_computed_cost_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_computed_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_current_cost_arr">
<code class="descname">set_current_cost_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_current_cost_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_current_cost_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_current_dist_arr">
<code class="descname">set_current_dist_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_current_dist_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_current_dist_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_predicted_log_arr">
<code class="descname">set_predicted_log_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_predicted_log_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_predicted_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_predicted_log_list">
<code class="descname">set_predicted_log_list</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_predicted_log_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_predicted_log_list" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_stocked_predicted_arr">
<code class="descname">set_stocked_predicted_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_stocked_predicted_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_stocked_predicted_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_var_arr">
<code class="descname">set_var_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_var_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_var_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_var_log_arr">
<code class="descname">set_var_log_arr</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_var_log_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_var_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.annealing_model.AnnealingModel.set_x">
<code class="descname">set_x</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/annealing_model.html#AnnealingModel.set_x"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.set_x" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.stocked_predicted_arr">
<code class="descname">stocked_predicted_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.stocked_predicted_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.var_arr">
<code class="descname">var_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.var_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.var_log_arr">
<code class="descname">var_log_arr</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.var_log_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.annealing_model.AnnealingModel.x">
<code class="descname">x</code><a class="headerlink" href="#pyqlearning.annealing_model.AnnealingModel.x" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyqlearning.deep_q_learning">
<span id="pyqlearning-deep-q-learning-module"></span><h2>pyqlearning.deep_q_learning module<a class="headerlink" href="#module-pyqlearning.deep_q_learning" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pyqlearning.deep_q_learning.DeepQLearning">
<em class="property">class </em><code class="descclassname">pyqlearning.deep_q_learning.</code><code class="descname">DeepQLearning</code><span class="sig-paren">(</span><em>function_approximator</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract base class to implement the Deep Q-Learning.</p>
<p>The Reinforcement learning theory presents several issues
from a perspective of deep learning theory(Mnih, V., et al. 2013).
Firstly, deep learning applications have required large amounts of
hand-labelled training data. Reinforcement learning algorithms,
on the other hand, must be able to learn from a scalar reward signal
that is frequently sparse, noisy and delayed.</p>
<p>The difference between the two theories is not only the type of data
but also the timing to be observed. The delay between taking actions and
receiving rewards, which can be thousands of timesteps long, seems particularly
daunting when compared to the direct association between inputs and targets found
in supervised learning.</p>
<p>Another issue is that deep learning algorithms assume the data samples to be independent,
while in reinforcement learning one typically encounters sequences of highly correlated
states. Furthermore, in Reinforcement learning, the data distribution changes as the
algorithm learns new behaviours, presenting aspects of recursive learning, which can be
problematic for deep learning methods that assume a fixed underlying distribution.</p>
<p>Increasing the complexity of states/actions is equivalent to increasing the number of
combinations of states/actions. If the value function is continuous and granularities of
states/actions are extremely fine, the combinatorial explosion will be encountered.
In other words, this basic approach is totally impractical, because the state/action-value
function is estimated separately for each sequence, without any <strong>generalisation</strong>. Instead,
it is common to use a <strong>function approximator</strong> to estimate the state/action-value function.</p>
<p>Considering many variable parts and functional extensions in the Deep Q-learning paradigm
from perspective of commonality/variability analysis in order to practice
object-oriented design, this abstract class defines the skeleton of a Deep Q-Learning
algorithm in an operation, deferring some steps in concrete variant algorithms
such as Epsilon Deep Q-Network to client subclasses. This abstract class in this library
lets subclasses redefine certain steps of a Deep Q-Learning algorithm without changing
the algorithm’s structure.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Egorov, M. (2016). Multi-agent deep reinforcement learning.(URL: <a class="reference external" href="https://pdfs.semanticscholar.org/dd98/9d94613f439c05725bad958929357e365084.pdf">https://pdfs.semanticscholar.org/dd98/9d94613f439c05725bad958929357e365084.pdf</a>)</li>
<li>Gupta, J. K., Egorov, M., &amp; Kochenderfer, M. (2017, May). Cooperative multi-agent control using deep reinforcement learning. In International Conference on Autonomous Agents and Multiagent Systems (pp. 66-83). Springer, Cham.</li>
<li>Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., &amp; Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.</li>
</ul>
<dl class="attribute">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.alpha_value">
<code class="descname">alpha_value</code><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.check_the_end_flag">
<code class="descname">check_the_end_flag</code><span class="sig-paren">(</span><em>state_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.check_the_end_flag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.check_the_end_flag" title="Permalink to this definition">¶</a></dt>
<dd><p>Check the end flag.</p>
<p>If this return value is <cite>True</cite>, the learning is end.</p>
<p>As a rule, the learning can not be stopped.
This method should be overrided for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_arr</strong> – <cite>np.ndarray</cite> of state in <cite>self.t</cite>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">bool</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.extract_possible_actions">
<code class="descname">extract_possible_actions</code><span class="sig-paren">(</span><em>state_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.extract_possible_actions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.extract_possible_actions" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract possible actions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_arr</strong> – <cite>np.ndarray</cite> of state.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of actions.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.function_approximator">
<code class="descname">function_approximator</code><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.function_approximator" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.gamma_value">
<code class="descname">gamma_value</code><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.get_alpha_value">
<code class="descname">get_alpha_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.get_alpha_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.get_alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.get_function_approximator">
<code class="descname">get_function_approximator</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.get_function_approximator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.get_function_approximator" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.get_gamma_value">
<code class="descname">get_gamma_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.get_gamma_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.get_gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.get_q_logs_arr">
<code class="descname">get_q_logs_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.get_q_logs_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.get_q_logs_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>state_arr</em>, <em>limit=1000</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Learning and searching the optimal solution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_arr</strong> – <cite>np.ndarray</cite> of initial state.</li>
<li><strong>limit</strong> – The maximum number of iterative updates based on value iteration algorithms.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.learn_q">
<code class="descname">learn_q</code><span class="sig-paren">(</span><em>predicted_q_arr</em>, <em>real_q_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.learn_q"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.learn_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn Q with the function approximator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>predicted_q_arr</strong> – <cite>np.ndarray</cite> of predicted Q-Values.</li>
<li><strong>real_q_arr</strong> – <cite>np.ndarray</cite> of real Q-Values.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.observe_reward_value">
<code class="descname">observe_reward_value</code><span class="sig-paren">(</span><em>state_arr</em>, <em>action_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.observe_reward_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.observe_reward_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the reward value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_arr</strong> – <cite>np.ndarray</cite> of state.</li>
<li><strong>action_arr</strong> – <cite>np.ndarray</cite> of action.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Reward value.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.q_logs_arr">
<code class="descname">q_logs_arr</code><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.q_logs_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.select_action">
<code class="descname">select_action</code><span class="sig-paren">(</span><em>next_action_arr</em>, <em>next_q_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.select_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.select_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Select action by Q(state, action).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>next_action_arr</strong> – <cite>np.ndarray</cite> of actions.</li>
<li><strong>next_q_arr</strong> – <cite>np.ndarray</cite> of Q-Values.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Tuple(<cite>np.ndarray</cite> of action., Q-Value)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.set_alpha_value">
<code class="descname">set_alpha_value</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.set_alpha_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.set_alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>setter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.set_function_approximator">
<code class="descname">set_function_approximator</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.set_function_approximator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.set_function_approximator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.set_gamma_value">
<code class="descname">set_gamma_value</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.set_gamma_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.set_gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>setter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.set_q_logs_arr">
<code class="descname">set_q_logs_arr</code><span class="sig-paren">(</span><em>values</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.set_q_logs_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.set_q_logs_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.update_q">
<code class="descname">update_q</code><span class="sig-paren">(</span><em>predicted_q_arr</em>, <em>reward_value_arr</em>, <em>next_max_q_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.update_q"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.update_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Update Q.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>predicted_q_arr</strong> – <cite>np.ndarray</cite> of predicted Q-Values.</li>
<li><strong>reward_value_arr</strong> – <cite>np.ndarray</cite> of reward values.</li>
<li><strong>next_max_q_arr</strong> – <cite>np.ndarray</cite> of maximum Q-Values in next time step.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><cite>np.ndarray</cite> of real Q-Values.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.deep_q_learning.DeepQLearning.update_state">
<code class="descname">update_state</code><span class="sig-paren">(</span><em>state_arr</em>, <em>action_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/deep_q_learning.html#DeepQLearning.update_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.deep_q_learning.DeepQLearning.update_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Update state.</p>
<p>This method can be overrided for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_arr</strong> – <cite>np.ndarray</cite> of state in <cite>self.t</cite>.</li>
<li><strong>action_arr</strong> – <cite>np.ndarray</cite> of action in <cite>self.t</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><cite>np.ndarray</cite> of state in <cite>self.t+1</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyqlearning.function_approximator">
<span id="pyqlearning-function-approximator-module"></span><h2>pyqlearning.function_approximator module<a class="headerlink" href="#module-pyqlearning.function_approximator" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pyqlearning.function_approximator.FunctionApproximator">
<em class="property">class </em><code class="descclassname">pyqlearning.function_approximator.</code><code class="descname">FunctionApproximator</code><a class="reference internal" href="_modules/pyqlearning/function_approximator.html#FunctionApproximator"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.function_approximator.FunctionApproximator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>The interface of Function Approximators.</p>
<p>Typically, the Deep Q-Learning such as the Deep Q-Network uses the
Convolutional Neural Networks(CNN) as a function approximator
to solve problem setting of so-called Combination explosion.</p>
<p>But it is not inevitable to functionally reuse CNN as
a function approximator. In the above problem setting of
generalisation and Combination explosion, for instance,
Long Short-Term Memory(LSTM) networks, which is-a special
Reccurent Neural Network(RNN) structure, and CNN as a function
approximator are functionally equivalent. In the same problem
setting, functional equivalents can be functionally replaced.
Considering that the feature space of the rewards has the
time-series nature, LSTM will be more useful.</p>
<p>This interface defines methods to controll functionally equivalents
of CNN. <cite>DeepQLearning</cite> can be delegated an object that is-a this interface.
More detail, this interface defines a family of algorithms of Deep Learning,
such as LSTM, Convolutional LSTM(Xingjian, S. H. I. et al., 2015), and
CLDNN Architecture(Sainath, T. N, et al., 2015) encapsulate each one,
and make them interchangeable.  Strategy lets the function approximation
algorithm vary independently from the clients that use it.
Capture the abstraction in an interface, bury implementation details in derived classes.</p>
<p class="rubric">References</p>
<ul class="simple">
<li><a class="reference external" href="https://code.accel-brain.com/Deep-Learning-by-means-of-Design-Pattern/README.html">https://code.accel-brain.com/Deep-Learning-by-means-of-Design-Pattern/README.html</a></li>
<li><a class="reference external" href="https://code.accel-brain.com/Reinforcement-Learning/README.html#deep-q-network">https://code.accel-brain.com/Reinforcement-Learning/README.html#deep-q-network</a></li>
<li>[Egorov, M. (2016). Multi-agent deep reinforcement learning.](<a class="reference external" href="https://pdfs.semanticscholar.org/dd98/9d94613f439c05725bad958929357e365084.pdf">https://pdfs.semanticscholar.org/dd98/9d94613f439c05725bad958929357e365084.pdf</a>)</li>
<li>Gupta, J. K., Egorov, M., &amp; Kochenderfer, M. (2017, May). Cooperative multi-agent control using deep reinforcement learning. In International Conference on Autonomous Agents and Multiagent Systems (pp. 66-83). Springer, Cham.</li>
<li>Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., &amp; Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.</li>
<li>Sainath, T. N., Vinyals, O., Senior, A., &amp; Sak, H. (2015, April). Convolutional, long short-term memory, fully connected deep neural networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 4580-4584). IEEE.</li>
<li>Xingjian, S. H. I., Chen, Z., Wang, H., Yeung, D. Y., Wong, W. K., &amp; Woo, W. C. (2015). Convolutional LSTM network: A machine learning approach for precipitation nowcasting. In Advances in neural information processing systems (pp. 802-810).</li>
</ul>
<dl class="method">
<dt id="pyqlearning.function_approximator.FunctionApproximator.inference_q">
<code class="descname">inference_q</code><span class="sig-paren">(</span><em>next_action_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/function_approximator.html#FunctionApproximator.inference_q"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.function_approximator.FunctionApproximator.inference_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Infernce Q-Value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>next_action_arr</strong> – <cite>np.ndarray</cite> of action.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of Q-Values.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.function_approximator.FunctionApproximator.learn_q">
<code class="descname">learn_q</code><span class="sig-paren">(</span><em>predicted_q_arr</em>, <em>real_q_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/function_approximator.html#FunctionApproximator.learn_q"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.function_approximator.FunctionApproximator.learn_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Infernce Q-Value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>predicted_q_arr</strong> – <cite>np.ndarray</cite> of predicted Q-Values.</li>
<li><strong>real_q_arr</strong> – <cite>np.ndarray</cite> of real Q-Values.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.function_approximator.FunctionApproximator.model">
<code class="descname">model</code><a class="headerlink" href="#pyqlearning.function_approximator.FunctionApproximator.model" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>object</cite> of model as a function approximator.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyqlearning.q_learning">
<span id="pyqlearning-q-learning-module"></span><h2>pyqlearning.q_learning module<a class="headerlink" href="#module-pyqlearning.q_learning" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pyqlearning.q_learning.QLearning">
<em class="property">class </em><code class="descclassname">pyqlearning.q_learning.</code><code class="descname">QLearning</code><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Abstract base class and <cite>Template Method Pattern</cite> of Q-Learning.</p>
<p>According to the Reinforcement Learning problem settings, Q-Learning
is a kind of Temporal Difference learning(TD Learning) that can be
considered as hybrid of Monte Carlo method and Dynamic Programming method.
As Monte Carlo method, TD Learning algorithm can learn by experience
without model of environment. And this learning algorithm is functional
extension of bootstrap method as Dynamic Programming Method.</p>
<p>In this library, Q-Learning can be distinguished into Epsilon Greedy
Q-Leanring and Boltzmann Q-Learning. These algorithm is functionally equivalent
but their structures should be conceptually distinguished.</p>
<p>Considering many variable parts and functional extensions in the Q-learning paradigm
from perspective of commonality/variability analysis in order to practice
object-oriented design, this abstract class defines the skeleton of a Q-Learning
algorithm in an operation, deferring some steps in concrete variant algorithms
such as Epsilon Greedy Q-Leanring and Boltzmann Q-Learning to client subclasses.
This abstract class in this library lets subclasses redefine certain steps of
a Q-Learning algorithm without changing the algorithm’s structure.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Agrawal, S., &amp; Goyal, N. (2011). Analysis of Thompson sampling for the multi-armed bandit problem. arXiv preprint arXiv:1111.1797.</li>
<li>Bubeck, S., &amp; Cesa-Bianchi, N. (2012). Regret analysis of stochastic and nonstochastic multi-armed bandit problems. arXiv preprint arXiv:1204.5721.</li>
<li>Chapelle, O., &amp; Li, L. (2011). An empirical evaluation of thompson sampling. In Advances in neural information processing systems (pp. 2249-2257).</li>
<li>Du, K. L., &amp; Swamy, M. N. S. (2016). Search and optimization by metaheuristics (p. 434). New York City: Springer.</li>
<li>Kaufmann, E., Cappe, O., &amp; Garivier, A. (2012). On Bayesian upper confidence bounds for bandit problems. In International Conference on Artificial Intelligence and Statistics (pp. 592-600).</li>
<li>Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., &amp; Riedmiller, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602.</li>
<li>Richard Sutton and Andrew Barto (1998). Reinforcement Learning. MIT Press.</li>
<li>Watkins, C. J. C. H. (1989). Learning from delayed rewards (Doctoral dissertation, University of Cambridge).</li>
<li>Watkins, C. J., &amp; Dayan, P. (1992). Q-learning. Machine learning, 8(3-4), 279-292.</li>
<li>White, J. (2012). Bandit algorithms for website optimization. ” O’Reilly Media, Inc.”.</li>
</ul>
<dl class="attribute">
<dt id="pyqlearning.q_learning.QLearning.alpha_value">
<code class="descname">alpha_value</code><a class="headerlink" href="#pyqlearning.q_learning.QLearning.alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.check_the_end_flag">
<code class="descname">check_the_end_flag</code><span class="sig-paren">(</span><em>state_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.check_the_end_flag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.check_the_end_flag" title="Permalink to this definition">¶</a></dt>
<dd><p>Check the end flag.</p>
<p>If this return value is <cite>True</cite>, the learning is end.</p>
<p>As a rule, the learning can not be stopped.
This method should be overrided for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_key</strong> – The key of state in <cite>self.t</cite>.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">bool</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.extract_possible_actions">
<code class="descname">extract_possible_actions</code><span class="sig-paren">(</span><em>state_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.extract_possible_actions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.extract_possible_actions" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract the list of the possible action in <cite>self.t+1</cite>.</p>
<p>Abstract method for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>The key of state in self.t+1.</strong> (<em>state_key</em>) – </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>list</cite> of the possible actions in <cite>self.t+1</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.extract_q_df">
<code class="descname">extract_q_df</code><span class="sig-paren">(</span><em>state_key</em>, <em>action_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.extract_q_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.extract_q_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract Q-Value from <cite>self.q_df</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>action_key</strong> – The key of action.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Q-Value.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.extract_r_df">
<code class="descname">extract_r_df</code><span class="sig-paren">(</span><em>state_key</em>, <em>r_value</em>, <em>action_key=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.extract_r_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.extract_r_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert or update R-Value in <cite>self.r_df</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>r_value</strong> – R-Value(Reward).</li>
<li><strong>action_key</strong> – The key of action if it is nesesary for the parametar of value function.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Exceptions:</dt>
<dd>TypeError:      If the type of <cite>r_value</cite> is not float.</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.q_learning.QLearning.gamma_value">
<code class="descname">gamma_value</code><a class="headerlink" href="#pyqlearning.q_learning.QLearning.gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.get_alpha_value">
<code class="descname">get_alpha_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.get_alpha_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.get_alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.get_gamma_value">
<code class="descname">get_gamma_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.get_gamma_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.get_gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.get_q_df">
<code class="descname">get_q_df</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.get_q_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.get_q_df" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.get_r_df">
<code class="descname">get_r_df</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.get_r_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.get_r_df" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.get_t">
<code class="descname">get_t</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.get_t"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.get_t" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Time.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>state_key</em>, <em>limit=1000</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Learning and searching the optimal solution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_key</strong> – Initial state.</li>
<li><strong>limit</strong> – The maximum number of iterative updates based on value iteration algorithms.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.normalize_q_value">
<code class="descname">normalize_q_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.normalize_q_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.normalize_q_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize q-value.
This method should be overrided for concreate usecases.</p>
<p>This method is called in each learning steps.</p>
<dl class="docutils">
<dt>For example:</dt>
<dd>self.q_df.q_value = self.q_df.q_value / self.q_df.q_value.sum()</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.normalize_r_value">
<code class="descname">normalize_r_value</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.normalize_r_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.normalize_r_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalize r-value.
This method should be overrided for concreate usecases.</p>
<p>This method is called in each learning steps.</p>
<dl class="docutils">
<dt>For example:</dt>
<dd>self.r_df.r_value = self.r_df.r_value / self.r_df.r_value.sum()</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.observe_reward_value">
<code class="descname">observe_reward_value</code><span class="sig-paren">(</span><em>state_key</em>, <em>action_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.observe_reward_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.observe_reward_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the reward value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>action_key</strong> – The key of action.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Reward value.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.predict_next_action">
<code class="descname">predict_next_action</code><span class="sig-paren">(</span><em>state_key</em>, <em>next_action_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.predict_next_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.predict_next_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict next action by Q-Learning.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_key</strong> – The key of state in <cite>self.t+1</cite>.</li>
<li><strong>next_action_list</strong> – The possible action in <cite>self.t+1</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The key of action.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.q_learning.QLearning.q_df">
<code class="descname">q_df</code><a class="headerlink" href="#pyqlearning.q_learning.QLearning.q_df" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.q_learning.QLearning.r_df">
<code class="descname">r_df</code><a class="headerlink" href="#pyqlearning.q_learning.QLearning.r_df" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.save_q_df">
<code class="descname">save_q_df</code><span class="sig-paren">(</span><em>state_key</em>, <em>action_key</em>, <em>q_value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.save_q_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.save_q_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert or update Q-Value in <cite>self.q_df</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_key</strong> – State.</li>
<li><strong>action_key</strong> – Action.</li>
<li><strong>q_value</strong> – Q-Value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Exceptions:</dt>
<dd>TypeError:      If the type of <cite>q_value</cite> is not float.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.save_r_df">
<code class="descname">save_r_df</code><span class="sig-paren">(</span><em>state_key</em>, <em>r_value</em>, <em>action_key=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.save_r_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.save_r_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert or update R-Value in <cite>self.r_df</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>r_value</strong> – R-Value(Reward).</li>
<li><strong>action_key</strong> – The key of action if it is nesesary for the parametar of value function.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="docutils">
<dt>Exceptions:</dt>
<dd>TypeError:      If the type of <cite>r_value</cite> is not float.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.select_action">
<code class="descname">select_action</code><span class="sig-paren">(</span><em>state_key</em>, <em>next_action_list</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.select_action"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.select_action" title="Permalink to this definition">¶</a></dt>
<dd><p>Select action by Q(state, action).</p>
<p>Abstract method for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>next_action_list</strong> – The possible action in <cite>self.t+1</cite>.
If the length of this list is zero, all action should be possible.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The key of action.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.set_alpha_value">
<code class="descname">set_alpha_value</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.set_alpha_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.set_alpha_value" title="Permalink to this definition">¶</a></dt>
<dd><p>setter
Learning rate.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.set_gamma_value">
<code class="descname">set_gamma_value</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.set_gamma_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.set_gamma_value" title="Permalink to this definition">¶</a></dt>
<dd><p>setter
Gamma value.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.set_q_df">
<code class="descname">set_q_df</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.set_q_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.set_q_df" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.set_r_df">
<code class="descname">set_r_df</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.set_r_df"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.set_r_df" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.set_t">
<code class="descname">set_t</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.set_t"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.set_t" title="Permalink to this definition">¶</a></dt>
<dd><p>setter
Time.</p>
</dd></dl>

<dl class="attribute">
<dt id="pyqlearning.q_learning.QLearning.t">
<code class="descname">t</code><a class="headerlink" href="#pyqlearning.q_learning.QLearning.t" title="Permalink to this definition">¶</a></dt>
<dd><p>getter
Time.</p>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.update_q">
<code class="descname">update_q</code><span class="sig-paren">(</span><em>state_key</em>, <em>action_key</em>, <em>reward_value</em>, <em>next_max_q</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.update_q"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.update_q" title="Permalink to this definition">¶</a></dt>
<dd><p>Update Q-Value.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>state_key</strong> – The key of state.</li>
<li><strong>action_key</strong> – The key of action.</li>
<li><strong>reward_value</strong> – R-Value(Reward).</li>
<li><strong>next_max_q</strong> – Maximum Q-Value.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.update_state">
<code class="descname">update_state</code><span class="sig-paren">(</span><em>state_key</em>, <em>action_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.update_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.update_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Update state.</p>
<p>This method can be overrided for concreate usecases.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>state_key</strong> – The key of state in <cite>self.t</cite>.</li>
<li><strong>action_key</strong> – The key of action in <cite>self.t</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The key of state in <cite>self.t+1</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pyqlearning.q_learning.QLearning.visualize_learning_result">
<code class="descname">visualize_learning_result</code><span class="sig-paren">(</span><em>state_key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pyqlearning/q_learning.html#QLearning.visualize_learning_result"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pyqlearning.q_learning.QLearning.visualize_learning_result" title="Permalink to this definition">¶</a></dt>
<dd><p>Visualize learning result.
This method should be overrided for concreate usecases.</p>
<p>This method is called in last learning steps.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_key</strong> – The key of state in <cite>self.t</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pyqlearning">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pyqlearning" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pyqlearning.annealingmodel.html" title="pyqlearning.annealingmodel package"
             >next</a> |</li>
        <li class="right" >
          <a href="README.html" title="Reinforcement Learning Library: pyqlearning"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pyqlearning  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>