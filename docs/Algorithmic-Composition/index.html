

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Algorithmic Composition or Automatic Composition Library: pycomposer &#8212; pycomposer  documentation</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pycomposer package" href="pycomposer.html" />
    <link rel="prev" title="Welcome to pycomposer’s documentation!" href="index.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pycomposer.html" title="pycomposer package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pycomposer’s documentation!"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pycomposer  documentation</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Algorithmic Composition or Automatic Composition Library: pycomposer</a><ul>
<li><a class="reference internal" href="#installation">Installation</a><ul>
<li><a class="reference internal" href="#source-code">Source code</a></li>
<li><a class="reference internal" href="#python-package-index-pypi">Python package index(PyPI)</a></li>
<li><a class="reference internal" href="#dependencies">Dependencies</a></li>
</ul>
</li>
<li><a class="reference internal" href="#documentation">Documentation</a></li>
<li><a class="reference internal" href="#description">Description</a><ul>
<li><a class="reference internal" href="#generative-adversarial-networks-gans">Generative Adversarial Networks(GANs)</a></li>
<li><a class="reference internal" href="#architecture-design">Architecture design</a></li>
<li><a class="reference internal" href="#data-representation">Data Representation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#usecase-composed-of-multi-instruments-tracks-by-conditional-gans">Usecase: Composed of multi instruments/tracks by Conditional GANs.</a><ul>
<li><a class="reference internal" href="#import-and-setup-modules">Import and setup modules.</a></li>
<li><a class="reference internal" href="#learning">Learning.</a></li>
<li><a class="reference internal" href="#inferencing">Inferencing.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#references">References</a><ul>
<li><a class="reference internal" href="#related-poc">Related PoC</a></li>
</ul>
</li>
<li><a class="reference internal" href="#author">Author</a></li>
<li><a class="reference internal" href="#author-uri">Author URI</a></li>
<li><a class="reference internal" href="#license">License</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Welcome to pycomposer’s documentation!</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pycomposer.html"
                        title="next chapter">pycomposer package</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/README.md.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="algorithmic-composition-or-automatic-composition-library-pycomposer">
<span id="algorithmic-composition-or-automatic-composition-library-pycomposer"></span><h1>Algorithmic Composition or Automatic Composition Library: pycomposer<a class="headerlink" href="#algorithmic-composition-or-automatic-composition-library-pycomposer" title="Permalink to this headline">¶</a></h1>
<p><code class="docutils literal notranslate"><span class="pre">pycomposer</span></code> is Python library for Algorithmic Composition or Automatic Composition based on the stochastic music theory and the Statistical machine learning problems. Especialy, this library provides apprication of the Algorithmic Composer based on Conditional Generative Adversarial Networks(Conditional GANs).</p>
<div class="section" id="installation">
<span id="installation"></span><h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Install using pip:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>pip install pycomposer
</pre></div>
</div>
<div class="section" id="source-code">
<span id="source-code"></span><h3>Source code<a class="headerlink" href="#source-code" title="Permalink to this headline">¶</a></h3>
<p>The source code is currently hosted on GitHub.</p>
<ul class="simple">
<li><a class="reference external" href="https://github.com/chimera0/accel-brain-code/tree/master/Algorithmic-Composition">accel-brain-code/Algorithmic Composition</a></li>
</ul>
</div>
<div class="section" id="python-package-index-pypi">
<span id="python-package-index-pypi"></span><h3>Python package index(PyPI)<a class="headerlink" href="#python-package-index-pypi" title="Permalink to this headline">¶</a></h3>
<p>Installers for the latest released version are available at the Python package index.</p>
<ul class="simple">
<li><a class="reference external" href="https://pypi.org/pypi/pycomposer/">pycomposer : Python Package Index</a></li>
</ul>
</div>
<div class="section" id="dependencies">
<span id="dependencies"></span><h3>Dependencies<a class="headerlink" href="#dependencies" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://github.com/numpy/numpy">numpy</a>: v1.13.3 or higher.</li>
<li><a class="reference external" href="https://github.com/pandas-dev/pandas">pandas</a>: v0.22.0 or higher.</li>
<li><a class="reference external" href="https://github.com/craffel/pretty-midi">pretty_midi</a>: latest.</li>
<li><a class="reference external" href="https://github.com/accel-brain/accel-brain-code/tree/master/Accel-Brain-Base">accel-brain-base</a>: v1.0.0 or higher.</li>
</ul>
</div>
</div>
<div class="section" id="documentation">
<span id="documentation"></span><h2>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h2>
<p>Full documentation is available on <a class="reference external" href="https://code.accel-brain.com/Algorithmic-Composition/">https://code.accel-brain.com/Algorithmic-Composition/</a> . This document contains information on functionally reusability, functional scalability and functional extensibility.</p>
</div>
<div class="section" id="description">
<span id="description"></span><h2>Description<a class="headerlink" href="#description" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">pycomposer</span></code> is Python library which provides wrapper classes for:</p>
<ul class="simple">
<li>reading sequencial data from MIDI files,</li>
<li>extracting feature points of observed data points from this sequencial data by <em>generative models</em>,</li>
<li>generating new sequencial data by compositions based on Generative models,</li>
<li>and converting the data into new MIDI file.</li>
</ul>
<div class="section" id="generative-adversarial-networks-gans">
<span id="generative-adversarial-networks-gans"></span><h3>Generative Adversarial Networks(GANs)<a class="headerlink" href="#generative-adversarial-networks-gans" title="Permalink to this headline">¶</a></h3>
<p>In order to realize these functions, this library implements algorithms of Algorithmic Composer based on Generative Adversarial Networks(GANs) (Goodfellow et al., 2014) framework which establishes a min-max adversarial game between two neural networks – a generative model, <code class="docutils literal notranslate"><span class="pre">G</span></code>, and a discriminative model, <code class="docutils literal notranslate"><span class="pre">D</span></code>. The discriminator model, <code class="docutils literal notranslate"><span class="pre">D(x)</span></code>, is a neural network that computes the probability that a observed data point <code class="docutils literal notranslate"><span class="pre">x</span></code> in data space is a sample from the data distribution (positive samples) that we are trying to model, rather than a sample from our generative model (negative samples). Concurrently, the generator uses a function <code class="docutils literal notranslate"><span class="pre">G(z)</span></code> that maps samples <code class="docutils literal notranslate"><span class="pre">z</span></code> from the prior <code class="docutils literal notranslate"><span class="pre">p(z)</span></code> to the data space. <code class="docutils literal notranslate"><span class="pre">G(z)</span></code> is trained to maximally confuse the discriminator into believing that samples it generates come from the data distribution. The generator is trained by leveraging the gradient of <code class="docutils literal notranslate"><span class="pre">D(x)</span></code> w.r.t. <code class="docutils literal notranslate"><span class="pre">x</span></code>, and using that to modify its parameters.</p>
</div>
<div class="section" id="architecture-design">
<span id="architecture-design"></span><h3>Architecture design<a class="headerlink" href="#architecture-design" title="Permalink to this headline">¶</a></h3>
<p>This library is designed following the above theory. The composer <code class="docutils literal notranslate"><span class="pre">GANComposer</span></code> learns observed data points drawn from a true distribution of input MIDI files and generates feature points drawn from a fake distribution that means such as Uniform distribution or Normal distribution, imitating the true MIDI files data.</p>
<p>The components included in this composer are functionally differentiated into three models.</p>
<ol class="simple">
<li><code class="docutils literal notranslate"><span class="pre">TrueSampler</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">Generator</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">Discriminator</span></code>.</li>
</ol>
<p>The function of <code class="docutils literal notranslate"><span class="pre">TrueSampler</span></code> is to draw samples from a true distribution of input MIDI files.  <code class="docutils literal notranslate"><span class="pre">Generator</span></code> has <code class="docutils literal notranslate"><span class="pre">NoiseSampler</span></code>s and draw fake samples from a Uniform distribution or Normal distribution by use it. And <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code> observes those input samples, trying discriminating true and fake data.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">Generator</span></code> and <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code> are built as LSTM networks, observing MIDI data separated by fixed sequence length and time resolution. While <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code> observes <code class="docutils literal notranslate"><span class="pre">Generator</span></code>’s observation to discrimine the output from true samples,  <code class="docutils literal notranslate"><span class="pre">Generator</span></code> observes <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code>’s observations to confuse <code class="docutils literal notranslate"><span class="pre">Discriminator</span></code>s judgments. In GANs framework, the mini-max game can be configured by the observations of observations.</p>
<p>After this game, the <code class="docutils literal notranslate"><span class="pre">Generator</span></code> will grow into a functional equivalent that enables to imitate the <code class="docutils literal notranslate"><span class="pre">TrueSampler</span></code> and makes it possible to compose similar but slightly different music by the imitation.</p>
</div>
<div class="section" id="data-representation">
<span id="data-representation"></span><h3>Data Representation<a class="headerlink" href="#data-representation" title="Permalink to this headline">¶</a></h3>
<p>Following MidiNet and MuseGAN(Dong, H. W., et al., 2018), this class consider bars as the basic compositional unit for the fact that harmonic changes usually occur at the boundaries of bars and that human beings often use bars as the building blocks when composing songs. The feature engineering in this class also is inspired by the Multi-track piano-roll representations in MuseGAN.</p>
<p>But their strategies of activation function did not apply to this library since its methods can cause information losses. The models just binarize the <code class="docutils literal notranslate"><span class="pre">Generator</span></code>’s output, which uses tanh as an activation function in the output layer, by a threshold at zero, or by deterministic or stochastic binary neurons(Bengio, Y., et al., 2018, Chung, J., et al., 2016), and ignore drawing a distinction the consonance and the dissonance.</p>
<p>This library simply uses the softmax strategy. This class stochastically selects a combination of pitches in each bars drawn by the true MIDI files data, based on the difference between consonance and dissonance intended by the composer of the MIDI files.</p>
</div>
</div>
<div class="section" id="usecase-composed-of-multi-instruments-tracks-by-conditional-gans">
<span id="usecase-composed-of-multi-instruments-tracks-by-conditional-gans"></span><h2>Usecase: Composed of multi instruments/tracks by Conditional GANs.<a class="headerlink" href="#usecase-composed-of-multi-instruments-tracks-by-conditional-gans" title="Permalink to this headline">¶</a></h2>
<p>Here, referring to the case of MidiNet model for symbolic-domain music generation(Yang, L. C., et al., 2017), Conditional GAN is used as an algorithm for composing music. MidiNet can be expanded to generate music with multiple MIDI channels (i.e. tracks), using convolutional and deconvolutional neural networks. MidiNet can be expanded to generate music with multiple MIDI channels (i.e. tracks), using convolutional and deconvolutional neural networks.</p>
<div>
<img src="https://storage.googleapis.com/accel-brain-code/Algorithmic-Composition/img/system_diagram_of_the_MidiNet.png" />
<p>Yang, L. C., Chou, S. Y., & Yang, Y. H. (2017). MidiNet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847., p3.</p>
</div><div class="section" id="import-and-setup-modules">
<span id="import-and-setup-modules"></span><h3>Import and setup modules.<a class="headerlink" href="#import-and-setup-modules" title="Permalink to this headline">¶</a></h3>
<p>Make settings for this library and for visualization.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="o">.</span><span class="n">figure_format</span> <span class="o">=</span> <span class="s2">&quot;retina&quot;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Import Python modules.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pycomposer.gancomposable.conditional_gan_composer</span> <span class="kn">import</span> <span class="n">ConditionalGANComposer</span>
</pre></div>
</div>
<p>Let’s make it possible to confirm later that learning is working according to GAN theory by the logger of Python.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">logging</span> <span class="kn">import</span> <span class="n">getLogger</span><span class="p">,</span> <span class="n">StreamHandler</span><span class="p">,</span> <span class="n">NullHandler</span><span class="p">,</span> <span class="n">DEBUG</span><span class="p">,</span> <span class="n">ERROR</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;pygan&quot;</span><span class="p">)</span>
<span class="n">handler</span> <span class="o">=</span> <span class="n">StreamHandler</span><span class="p">()</span>
<span class="n">handler</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>
</pre></div>
</div>
<p>Instantiate the required class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gan_composer</span> <span class="o">=</span> <span class="n">ConditionalGANComposer</span><span class="p">(</span>
    <span class="c1"># `list` of Midi files to learn.</span>
    <span class="n">midi_path_list</span><span class="o">=</span><span class="p">[</span>
        <span class="s2">&quot;../../../../Downloads/Beethoven_gekko_3_k.mid&quot;</span>
    <span class="p">],</span> 
    <span class="c1"># Batch size.</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="c1"># The length of sequence that LSTM networks will observe.</span>
    <span class="n">seq_len</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="c1"># Learning rate in `Generator` and `Discriminator`.</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
    <span class="c1"># Time fraction or time resolution (seconds).</span>
    <span class="n">time_fraction</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="learning">
<span id="learning"></span><h3>Learning.<a class="headerlink" href="#learning" title="Permalink to this headline">¶</a></h3>
<p>The learning algorithm is based on a mini-batch stochastic gradient descent training of generative adversarial nets. The number of steps to apply to the discriminator, <code class="docutils literal notranslate"><span class="pre">k_step</span></code>, is a hyperparameter. For instance, Goodfellow, I. et al.(2014) used <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">1</span></code>, the least expensive option. Not limited to this parameter, the appropriate value of the hyperparameter is unknown.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gan_composer</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span>
    <span class="c1"># The number of training iterations.</span>
    <span class="n">iter_n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
    <span class="c1"># The number of learning of the `discriminator`.</span>
    <span class="n">k_step</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inferencing">
<span id="inferencing"></span><h3>Inferencing.<a class="headerlink" href="#inferencing" title="Permalink to this headline">¶</a></h3>
<p>After learning, <code class="docutils literal notranslate"><span class="pre">gan_composer</span></code> enables to compose melody and new MIDI file by learned model. In relation to MIDI data, <code class="docutils literal notranslate"><span class="pre">pitch</span></code> is generated from a learned generation model. <code class="docutils literal notranslate"><span class="pre">start</span></code> and <code class="docutils literal notranslate"><span class="pre">end</span></code> are generated by calculating back from length of sequences and time resolution. On the other hand, <code class="docutils literal notranslate"><span class="pre">velocity</span></code> is sampled from Gaussian distribution.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">gan_composer</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span>
    <span class="c1"># Path to generated MIDI file.</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;path/to/new/midi/file.mid&quot;</span><span class="p">,</span> 
    <span class="c1"># Mean of velocity.</span>
    <span class="c1"># This class samples the velocity from a Gaussian distribution of </span>
    <span class="c1"># `velocity_mean` and `velocity_std`.</span>
    <span class="c1"># If `None`, the average velocity in MIDI files set to this parameter.</span>
    <span class="n">velocity_mean</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="c1"># Standard deviation(SD) of velocity.</span>
    <span class="c1"># This class samples the velocity from a Gaussian distribution of </span>
    <span class="c1"># `velocity_mean` and `velocity_std`.</span>
    <span class="c1"># If `None`, the SD of velocity in MIDI files set to this parameter.</span>
    <span class="n">velocity_std</span><span class="o">=</span><span class="bp">None</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Finally, new MIDI file will be stored in <code class="docutils literal notranslate"><span class="pre">file_path</span></code>.</p>
<p>If you want to know more detailed implementation and log visualization, see <a class="reference external" href="https://github.com/accel-brain/accel-brain-code/blob/master/Algorithmic-Composition/demo/Algorithmic_composition_by_conditional_GAN_like_MidiNet.ipynb">my notebook</a>.</p>
</div>
</div>
<div class="section" id="references">
<span id="references"></span><h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Bengio, Y., Léonard, N., &amp; Courville, A. (2013). Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432.</li>
<li>Chung, J., Ahn, S., &amp; Bengio, Y. (2016). Hierarchical multiscale recurrent neural networks. arXiv preprint arXiv:1609.01704.</li>
<li>Dong, H. W., Hsiao, W. Y., Yang, L. C., &amp; Yang, Y. H. (2018, April). MuseGAN: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment. In Thirty-Second AAAI Conference on Artificial Intelligence.</li>
<li>Fang, W., Zhang, F., Sheng, V. S., &amp; Ding, Y. (2018). A method for improving CNN-based image recognition using DCGAN. Comput. Mater. Contin, 57, 167-178.</li>
<li>Gauthier, J. (2014). Conditional generative adversarial nets for convolutional face generation. Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester, 2014(5), 2.</li>
<li>Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., … &amp; Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680).</li>
<li>Long, J., Shelhamer, E., &amp; Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3431-3440).</li>
<li>Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., &amp; Frey, B. (2015). Adversarial autoencoders. arXiv preprint arXiv:1511.05644.</li>
<li>Mirza, M., &amp; Osindero, S. (2014). Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784.</li>
<li>Yang, L. C., Chou, S. Y., &amp; Yang, Y. H. (2017). MidiNet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847.</li>
</ul>
<div class="section" id="related-poc">
<span id="related-poc"></span><h3>Related PoC<a class="headerlink" href="#related-poc" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><a class="reference external" href="https://accel-brain.com/das-theologische-bild-genialer-physiker-in-der-quantenmechanik-und-der-statistischen-mechanik-und-thermodynamik/">量子力学、統計力学、熱力学における天才物理学者たちの神学的な形象について</a> (Japanese)<ul>
<li><a class="reference external" href="https://accel-brain.com/das-theologische-bild-genialer-physiker-in-der-quantenmechanik-und-der-statistischen-mechanik-und-thermodynamik/maxwell-damon/">「マクスウェルの悪魔」、力学の基礎法則としての神</a></li>
</ul>
</li>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/">深層強化学習のベイズ主義的な情報探索に駆動された自然言語処理の意味論</a> (Japanese)<ul>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/tiefe-boltzmann-maschine-als-selbstkodierer/">平均場近似推論の統計力学、自己符号化器としての深層ボルツマンマシン</a></li>
<li><a class="reference external" href="https://accel-brain.com/semantics-of-natural-language-processing-driven-by-bayesian-information-search-by-deep-reinforcement-learning/regularisierungsproblem-und-gan/">正則化問題における敵対的生成ネットワーク(GANs)と敵対的自己符号化器(AAEs)のネットワーク構造</a></li>
</ul>
</li>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/">「人工の理想」を背景とした「万物照応」のデータモデリング</a> (Japanese)<ul>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/algorithmus-der-mimetischen-innervation/">模倣のアルゴリズムとアルゴリズムの模倣</a></li>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/sozialstruktur-von-random-walk-und-semantik-der-dow-theorie/">ランダムウォークの社会構造とダウ理論の意味論、再帰的ニューラルネットワークの価格変動モデルから敵対的生成ネットワーク（GAN）へ</a></li>
<li><a class="reference external" href="https://accel-brain.com/data-modeling-von-korrespondenz-in-artificial-paradise/epische-musik/">叙事的な音楽、マトリックスのリズム</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="author">
<span id="author"></span><h2>Author<a class="headerlink" href="#author" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>accel-brain</li>
</ul>
</div>
<div class="section" id="author-uri">
<span id="author-uri"></span><h2>Author URI<a class="headerlink" href="#author-uri" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>https://accel-brain.co.jp/</li>
<li>https://accel-brain.com/</li>
</ul>
</div>
<div class="section" id="license">
<span id="license"></span><h2>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>GNU General Public License v2.0</li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pycomposer.html" title="pycomposer package"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Welcome to pycomposer’s documentation!"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pycomposer  documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>