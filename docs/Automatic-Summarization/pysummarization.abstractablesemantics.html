

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pysummarization.abstractablesemantics package &#8212; pysummarization  documentation</title>
    <link rel="stylesheet" href="_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pysummarization.computabledistance package" href="pysummarization.computabledistance.html" />
    <link rel="prev" title="pysummarization.abstractabledoc package" href="pysummarization.abstractabledoc.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pysummarization.computabledistance.html" title="pysummarization.computabledistance package"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="pysummarization.abstractabledoc.html" title="pysummarization.abstractabledoc package"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pysummarization.html" accesskey="U">pysummarization package</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="pysummarization.abstractabledoc.html"
                        title="previous chapter">pysummarization.abstractabledoc package</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="pysummarization.computabledistance.html"
                        title="next chapter">pysummarization.computabledistance package</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pysummarization-abstractablesemantics-package">
<h1>pysummarization.abstractablesemantics package<a class="headerlink" href="#pysummarization-abstractablesemantics-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-pysummarization.abstractablesemantics.enc_dec_ad">
<span id="pysummarization-abstractablesemantics-enc-dec-ad-module"></span><h2>pysummarization.abstractablesemantics.enc_dec_ad module<a class="headerlink" href="#module-pysummarization.abstractablesemantics.enc_dec_ad" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD">
<em class="property">class </em><code class="descclassname">pysummarization.abstractablesemantics.enc_dec_ad.</code><code class="descname">EncDecAD</code><span class="sig-paren">(</span><em>normal_prior_flag=False</em>, <em>encoder_decoder_controller=None</em>, <em>input_neuron_count=20</em>, <em>hidden_neuron_count=20</em>, <em>weight_limit=10000000000.0</em>, <em>dropout_rate=0.5</em>, <em>pre_learning_epochs=1000</em>, <em>epochs=100</em>, <em>batch_size=20</em>, <em>learning_rate=1e-05</em>, <em>learning_attenuate_rate=1.0</em>, <em>attenuate_epoch=50</em>, <em>seq_len=8</em>, <em>bptt_tau=8</em>, <em>test_size_rate=0.3</em>, <em>tol=0.0</em>, <em>tld=100.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pysummarization.html#pysummarization.abstractable_semantics.AbstractableSemantics" title="pysummarization.abstractable_semantics.AbstractableSemantics"><code class="xref py py-class docutils literal notranslate"><span class="pre">pysummarization.abstractable_semantics.AbstractableSemantics</span></code></a></p>
<p>LSTM-based Encoder/Decoder scheme for Anomaly Detection (EncDec-AD).</p>
<p>This library applies the Encoder-Decoder scheme for Anomaly Detection (EncDec-AD)
to text summarizations by intuition. In this scheme, LSTM-based Encoder/Decoder
or so-called the sequence-to-sequence(Seq2Seq) model learns to reconstruct normal time-series behavior,
and thereafter uses reconstruction error to detect anomalies.</p>
<p>Malhotra, P., et al. (2016) showed that EncDecAD paradigm is robust and
can detect anomalies from predictable, unpredictable, periodic, aperiodic,
and quasi-periodic time-series. Further, they showed that the paradigm is able to
detect anomalies from short time-series (length as small as 30) as well as long
time-series (length as large as 500).</p>
<p>This library refers to the intuitive insight in relation to the use case of
reconstruction error to detect anomalies above to apply the model to text summarization.
As exemplified by Seq2Seq paradigm, document and sentence which contain tokens of text
can be considered as time-series features. The anomalies data detected by EncDec-AD
should have to express something about the text.</p>
<p>From the above analogy, this library introduces two conflicting intuitions. On the one hand,
the anomalies data may catch observer’s eye from the viewpoints of rarity or amount of information
as the indicator of natural language processing like TF-IDF shows. On the other hand,
the anomalies data may be ignorable noise as mere outlier.</p>
<p>In any case, this library deduces the function and potential of EncDec-AD in text summarization
is to draw the distinction of normal and anomaly texts and is to filter the one from the other.</p>
<p>Note that the model in this library and Malhotra, P., et al. (2016) are different in some respects
from the relation with the specification of the Deep Learning library: [pydbm](<a class="reference external" href="https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern">https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern</a>).
First, weight matrix of encoder and decoder is not shered. Second, it is possible to
introduce regularization techniques which are not discussed in Malhotra, P., et al. (2016)
such as the dropout, the gradient clipping, and limitation of weights.
Third, the loss function for reconstruction error is not limited to the L2 norm.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Malhotra, P., Ramakrishnan, A., Anand, G., Vig, L., Agarwal, P., &amp; Shroff, G. (2016). LSTM-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148.</li>
</ul>
<dl class="attribute">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.encoder_decoder_controller">
<code class="descname">encoder_decoder_controller</code><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.encoder_decoder_controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.get_encoder_decoder_controller">
<code class="descname">get_encoder_decoder_controller</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD.get_encoder_decoder_controller"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.get_encoder_decoder_controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>observed_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Infernece by the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>observed_arr</strong> – <cite>np.ndarray</cite> of observed data points.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of inferenced feature points.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>observed_arr</em>, <em>target_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Training the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>observed_arr</strong> – <cite>np.ndarray</cite> of observed data points.</li>
<li><strong>target_arr</strong> – <cite>np.ndarray</cite> of target labeled data.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.set_readonly">
<code class="descname">set_readonly</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD.set_readonly"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.set_readonly" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.summarize">
<code class="descname">summarize</code><span class="sig-paren">(</span><em>test_arr</em>, <em>vectorizable_token</em>, <em>sentence_list</em>, <em>limit=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/enc_dec_ad.html#EncDecAD.summarize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.enc_dec_ad.EncDecAD.summarize" title="Permalink to this definition">¶</a></dt>
<dd><p>Summarize input document.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_arr</strong> – <cite>np.ndarray</cite> of observed data points..</li>
<li><strong>vectorizable_token</strong> – is-a <cite>VectorizableToken</cite>.</li>
<li><strong>sentence_list</strong> – <cite>list</cite> of all sentences.</li>
<li><strong>limit</strong> – The number of selected abstract sentence.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><cite>np.ndarray</cite> of scores.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pysummarization.abstractablesemantics.re_seq_2_seq">
<span id="pysummarization-abstractablesemantics-re-seq-2-seq-module"></span><h2>pysummarization.abstractablesemantics.re_seq_2_seq module<a class="headerlink" href="#module-pysummarization.abstractablesemantics.re_seq_2_seq" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq">
<em class="property">class </em><code class="descclassname">pysummarization.abstractablesemantics.re_seq_2_seq.</code><code class="descname">ReSeq2Seq</code><span class="sig-paren">(</span><em>margin_param=0.01</em>, <em>retrospective_lambda=0.5</em>, <em>retrospective_eta=0.5</em>, <em>encoder_decoder_controller=None</em>, <em>retrospective_encoder=None</em>, <em>input_neuron_count=20</em>, <em>hidden_neuron_count=20</em>, <em>weight_limit=10000000000.0</em>, <em>dropout_rate=0.5</em>, <em>pre_learning_epochs=1000</em>, <em>epochs=100</em>, <em>batch_size=20</em>, <em>learning_rate=1e-05</em>, <em>learning_attenuate_rate=1.0</em>, <em>attenuate_epoch=50</em>, <em>grad_clip_threshold=10000000000.0</em>, <em>seq_len=8</em>, <em>bptt_tau=8</em>, <em>test_size_rate=0.3</em>, <em>tol=0.0</em>, <em>tld=100.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="pysummarization.html#pysummarization.abstractable_semantics.AbstractableSemantics" title="pysummarization.abstractable_semantics.AbstractableSemantics"><code class="xref py py-class docutils literal notranslate"><span class="pre">pysummarization.abstractable_semantics.AbstractableSemantics</span></code></a></p>
<p>A retrospective sequence-to-sequence learning(re-seq2seq).</p>
<p>The concept of the re-seq2seq(Zhang, K. et al., 2018) provided inspiration to this library.
This model is a new sequence learning model mainly in the field of Video Summarizations.
“The key idea behind re-seq2seq is to measure how well the machine-generated summary
is similar to the original video in an abstract semantic space” (Zhang, K. et al., 2018, p3).</p>
<p>The encoder of a seq2seq model observes the original video and output feature points
which represents the semantic meaning of the observed data points.
Then the feature points is observed by the decoder of this model.
Additionally, in the re-seq2seq model, the outputs of the decoder is propagated
to a retrospective encoder, which infers feature points to represent the
semantic meaning of the summary. “If the summary preserves the important and
relevant information in the original video, then we should expect that the
two embeddings are similar (e.g. in Euclidean distance)” (Zhang, K. et al., 2018, p3).</p>
<p>This library refers to this intuitive insight above to apply the model to text summarizations.
Like videos, semantic feature representation based on representation learning of manifolds
is also possible in text summarizations.</p>
<p>The intuition in the design of their loss function is also suggestive.
“The intuition behind our modeling is that the outputs should convey
the same amount of information as the inputs. For summarization,
this is precisely the goal: a good summary should be such that after viewing
the summary, users would get about the same amount of information as if they
had viewed the original video” (Zhang, K. et al., 2018, p7).</p>
<p>But the model in this library and Zhang, K. et al.(2018) are different in some respects
from the relation with the specification of the Deep Learning library: [pydbm](<a class="reference external" href="https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern">https://github.com/chimera0/accel-brain-code/tree/master/Deep-Learning-by-means-of-Design-Pattern</a>).
First, Encoder/Decoder based on LSTM is not designed as a hierarchical structure.
Second, it is possible to introduce regularization techniques which are not discussed in
Zhang, K. et al.(2018) such as the dropout, the gradient clipping, and limitation of weights.
Third, the regression loss function for matching summaries is simplified in terms of
calculation efficiency in this library.</p>
<p class="rubric">References</p>
<ul class="simple">
<li>Zhang, K., Grauman, K., &amp; Sha, F. (2018). Retrospective Encoders for Video Summarization. In Proceedings of the European Conference on Computer Vision (ECCV) (pp. 383-399).</li>
</ul>
<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.back_propagation">
<code class="descname">back_propagation</code><span class="sig-paren">(</span><em>delta_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.back_propagation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.back_propagation" title="Permalink to this definition">¶</a></dt>
<dd><p>Back propagation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>delta_output_arr</strong> – Delta.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">Tuple data.
- decoder’s <cite>list</cite> of gradations,
- encoder’s <cite>np.ndarray</cite> of Delta,
- encoder’s <cite>list</cite> of gradations.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.compute_retrospective_loss">
<code class="descname">compute_retrospective_loss</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.compute_retrospective_loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.compute_retrospective_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute retrospective loss.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The tuple data.
- <cite>np.ndarray</cite> of delta.
- <cite>np.ndarray</cite> of losses of each batch.
- float of loss of all batch.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.encoder_decoder_controller">
<code class="descname">encoder_decoder_controller</code><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.encoder_decoder_controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_encoder_decoder_controller">
<code class="descname">get_encoder_decoder_controller</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.get_encoder_decoder_controller"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_encoder_decoder_controller" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_logs_arr">
<code class="descname">get_logs_arr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.get_logs_arr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_logs_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_retrospective_encoder">
<code class="descname">get_retrospective_encoder</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.get_retrospective_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.get_retrospective_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>observed_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.inference"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Infernece by the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>observed_arr</strong> – <cite>np.ndarray</cite> of observed data points.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><cite>np.ndarray</cite> of inferenced feature points.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn">
<code class="descname">learn</code><span class="sig-paren">(</span><em>observed_arr</em>, <em>target_arr</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.learn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn" title="Permalink to this definition">¶</a></dt>
<dd><p>Training the model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>observed_arr</strong> – <cite>np.ndarray</cite> of observed data points.</li>
<li><strong>target_arr</strong> – <cite>np.ndarray</cite> of target labeled data.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn_generated">
<code class="descname">learn_generated</code><span class="sig-paren">(</span><em>feature_generator</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.learn_generated"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.learn_generated" title="Permalink to this definition">¶</a></dt>
<dd><p>Learn features generated by <cite>FeatureGenerator</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>feature_generator</strong> – is-a <cite>FeatureGenerator</cite>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.logs_arr">
<code class="descname">logs_arr</code><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.logs_arr" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.optimize">
<code class="descname">optimize</code><span class="sig-paren">(</span><em>re_encoder_grads_list</em>, <em>decoder_grads_list</em>, <em>encoder_grads_list</em>, <em>learning_rate</em>, <em>epoch</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.optimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Back propagation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>re_encoder_grads_list</strong> – re-encoder’s <cite>list</cite> of graduations.</li>
<li><strong>decoder_grads_list</strong> – decoder’s <cite>list</cite> of graduations.</li>
<li><strong>encoder_grads_list</strong> – encoder’s <cite>list</cite> of graduations.</li>
<li><strong>learning_rate</strong> – Learning rate.</li>
<li><strong>epoch</strong> – Now epoch.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.retrospective_encoder">
<code class="descname">retrospective_encoder</code><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.retrospective_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>getter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.set_readonly">
<code class="descname">set_readonly</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.set_readonly"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.set_readonly" title="Permalink to this definition">¶</a></dt>
<dd><p>setter</p>
</dd></dl>

<dl class="method">
<dt id="pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.summarize">
<code class="descname">summarize</code><span class="sig-paren">(</span><em>test_arr</em>, <em>vectorizable_token</em>, <em>sentence_list</em>, <em>limit=5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/pysummarization/abstractablesemantics/re_seq_2_seq.html#ReSeq2Seq.summarize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#pysummarization.abstractablesemantics.re_seq_2_seq.ReSeq2Seq.summarize" title="Permalink to this definition">¶</a></dt>
<dd><p>Summarize input document.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_arr</strong> – <cite>np.ndarray</cite> of observed data points..</li>
<li><strong>vectorizable_token</strong> – is-a <cite>VectorizableToken</cite>.</li>
<li><strong>sentence_list</strong> – <cite>list</cite> of all sentences.</li>
<li><strong>limit</strong> – The number of selected abstract sentence.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><cite>list</cite> of <cite>str</cite> of abstract sentences.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-pysummarization.abstractablesemantics">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-pysummarization.abstractablesemantics" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="pysummarization.computabledistance.html" title="pysummarization.computabledistance package"
             >next</a> |</li>
        <li class="right" >
          <a href="pysummarization.abstractabledoc.html" title="pysummarization.abstractabledoc package"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="pysummarization.html" >pysummarization package</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>