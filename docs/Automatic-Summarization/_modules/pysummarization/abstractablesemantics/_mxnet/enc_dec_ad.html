

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>pysummarization.abstractablesemantics._mxnet.enc_dec_ad &#8212; pysummarization  documentation</title>
    <link rel="stylesheet" href="../../../../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for pysummarization.abstractablesemantics._mxnet.enc_dec_ad</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="k">import</span> <span class="n">getLogger</span>
<span class="kn">from</span> <span class="nn">logging</span> <span class="k">import</span> <span class="n">getLogger</span><span class="p">,</span> <span class="n">StreamHandler</span><span class="p">,</span> <span class="n">NullHandler</span><span class="p">,</span> <span class="n">DEBUG</span><span class="p">,</span> <span class="n">ERROR</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">import</span> <span class="nn">mxnet.ndarray</span> <span class="k">as</span> <span class="nn">nd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon.nn</span> <span class="k">import</span> <span class="n">Conv2D</span>

<span class="kn">from</span> <span class="nn">accelbrainbase.computableloss._mxnet.l2_norm_loss</span> <span class="k">import</span> <span class="n">L2NormLoss</span>
<span class="kn">from</span> <span class="nn">accelbrainbase.extractabledata.unlabeled_csv_extractor</span> <span class="k">import</span> <span class="n">UnlabeledCSVExtractor</span>
<span class="kn">from</span> <span class="nn">accelbrainbase.iteratabledata._mxnet.unlabeled_sequential_csv_iterator</span> <span class="k">import</span> <span class="n">UnlabeledSequentialCSVIterator</span>
<span class="kn">from</span> <span class="nn">accelbrainbase.noiseabledata._mxnet.gauss_noise</span> <span class="k">import</span> <span class="n">GaussNoise</span>
<span class="kn">from</span> <span class="nn">accelbrainbase.observabledata._mxnet.lstm_networks</span> <span class="k">import</span> <span class="n">LSTMNetworks</span>
<span class="kn">from</span> <span class="nn">accelbrainbase.observabledata._mxnet.lstmnetworks.encoder_decoder</span> <span class="k">import</span> <span class="n">EncoderDecoder</span>

<span class="kn">from</span> <span class="nn">pysummarization.abstractable_semantics</span> <span class="k">import</span> <span class="n">AbstractableSemantics</span>
<span class="kn">from</span> <span class="nn">pysummarization.vectorizable_token</span> <span class="k">import</span> <span class="n">VectorizableToken</span>


<div class="viewcode-block" id="EncDecAD"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD">[docs]</a><span class="k">class</span> <span class="nc">EncDecAD</span><span class="p">(</span><span class="n">AbstractableSemantics</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    LSTM-based Encoder/Decoder scheme for Anomaly Detection (EncDec-AD).</span>

<span class="sd">    This library applies the Encoder-Decoder scheme for Anomaly Detection (EncDec-AD)</span>
<span class="sd">    to text summarizations by intuition. In this scheme, LSTM-based Encoder/Decoder </span>
<span class="sd">    or so-called the sequence-to-sequence(Seq2Seq) model learns to reconstruct normal time-series behavior,</span>
<span class="sd">    and thereafter uses reconstruction error to detect anomalies.</span>
<span class="sd">    </span>
<span class="sd">    Malhotra, P., et al. (2016) showed that EncDecAD paradigm is robust and </span>
<span class="sd">    can detect anomalies from predictable, unpredictable, periodic, aperiodic, </span>
<span class="sd">    and quasi-periodic time-series. Further, they showed that the paradigm is able to </span>
<span class="sd">    detect anomalies from short time-series (length as small as 30) as well as long </span>
<span class="sd">    time-series (length as large as 500).</span>

<span class="sd">    This library refers to the intuitive insight in relation to the use case of </span>
<span class="sd">    reconstruction error to detect anomalies above to apply the model to text summarization.</span>
<span class="sd">    As exemplified by Seq2Seq paradigm, document and sentence which contain tokens of text</span>
<span class="sd">    can be considered as time-series features. The anomalies data detected by EncDec-AD </span>
<span class="sd">    should have to express something about the text.</span>

<span class="sd">    From the above analogy, this library introduces two conflicting intuitions. On the one hand,</span>
<span class="sd">    the anomalies data may catch observer&#39;s eye from the viewpoints of rarity or amount of information</span>
<span class="sd">    as the indicator of natural language processing like TF-IDF shows. On the other hand,</span>
<span class="sd">    the anomalies data may be ignorable noise as mere outlier.</span>
<span class="sd">    </span>
<span class="sd">    In any case, this library deduces the function and potential of EncDec-AD in text summarization</span>
<span class="sd">    is to draw the distinction of normal and anomaly texts and is to filter the one from the other.</span>

<span class="sd">    References:</span>
<span class="sd">        - Malhotra, P., Ramakrishnan, A., Anand, G., Vig, L., Agarwal, P., &amp; Shroff, G. (2016). LSTM-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Logs of accuracy.</span>
    <span class="n">__logs_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">__ctx</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">gpu</span><span class="p">()</span>

<div class="viewcode-block" id="EncDecAD.get_ctx"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.get_ctx">[docs]</a>    <span class="k">def</span> <span class="nf">get_ctx</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter for `mx.gpu()` or `mx.cpu()`. &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__ctx</span></div>

<div class="viewcode-block" id="EncDecAD.set_ctx"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.set_ctx">[docs]</a>    <span class="k">def</span> <span class="nf">set_ctx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; setter for `mx.gpu()` or `mx.cpu()`. &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__ctx</span> <span class="o">=</span> <span class="n">value</span></div>

    <span class="n">ctx</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_ctx</span><span class="p">,</span> <span class="n">set_ctx</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">computable_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">normal_prior_flag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">encoder_decoder_controller</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">output_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Init.</span>

<span class="sd">        Args:</span>
<span class="sd">            computable_loss:                is-a `ComputableLoss`.</span>
<span class="sd">            normal_prior_flag:              If `True`, this class will select abstract sentence</span>
<span class="sd">                                            from sentences with low reconstruction error.</span>

<span class="sd">            encoder_decoder_controller:     is-a `EncoderDecoderController`.</span>
<span class="sd">            hidden_neuron_count:            The number of units in hidden layers.</span>
<span class="sd">            output_neuron_count:            The number of units in output layers.</span>

<span class="sd">            dropout_rate:                   Probability of dropout.</span>
<span class="sd">            epochs:                         The epochs in mini-batch training Encoder/Decoder and retrospective encoder.</span>
<span class="sd">            batch_size:                     Batch size.</span>
<span class="sd">            learning_rate:                  Learning rate.</span>
<span class="sd">            learning_attenuate_rate:        Attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>
<span class="sd">            attenuate_epoch:                Attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>
<span class="sd">                                            </span>

<span class="sd">            seq_len:                        The length of sequneces in Decoder with Attention model.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="n">computable_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">computable_loss</span> <span class="o">=</span> <span class="n">L2NormLoss</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__normal_prior_flag</span> <span class="o">=</span> <span class="n">normal_prior_flag</span>
        <span class="k">if</span> <span class="n">encoder_decoder_controller</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__build_encoder_decoder_controller</span><span class="p">(</span>
                <span class="n">computable_loss</span><span class="o">=</span><span class="n">computable_loss</span><span class="p">,</span>
                <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
                <span class="n">output_neuron_count</span><span class="o">=</span><span class="n">output_neuron_count</span><span class="p">,</span>
                <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
                <span class="n">attenuate_epoch</span><span class="o">=</span><span class="n">attenuate_epoch</span><span class="p">,</span>
                <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="n">learning_attenuate_rate</span><span class="p">,</span>
                <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">encoder_decoder_controller</span><span class="p">,</span> <span class="n">EncoderDecoderController</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span> <span class="o">=</span> <span class="n">encoder_decoder_controller</span>

        <span class="n">logger</span> <span class="o">=</span> <span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;accelbrainbase&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logger</span> <span class="o">=</span> <span class="n">logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__logs_tuple_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__computable_loss</span> <span class="o">=</span> <span class="n">computable_loss</span>

    <span class="k">def</span> <span class="nf">__build_encoder_decoder_controller</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">computable_loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">hidden_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">output_neuron_count</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span>
        <span class="n">attenuate_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">seq_len</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">encoder</span> <span class="o">=</span> <span class="n">LSTMNetworks</span><span class="p">(</span>
            <span class="c1"># is-a `ComputableLoss` or `mxnet.gluon.loss`.</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">computable_loss</span><span class="p">,</span>
            <span class="c1"># `int` of batch size.</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="c1"># `int` of the length of series.</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
            <span class="c1"># `int` of the number of units in hidden layer.</span>
            <span class="n">hidden_n</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="c1"># `float` of dropout rate.</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` </span>
            <span class="c1"># that activates observed data points.</span>
            <span class="n">observed_activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in input gate.</span>
            <span class="n">input_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in forget gate.</span>
            <span class="n">forget_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in output gate.</span>
            <span class="n">output_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in hidden layer.</span>
            <span class="n">hidden_activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
            <span class="c1"># `bool` that means this class has output layer or not.</span>
            <span class="n">output_layer_flag</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="c1"># Call `mxnet.gluon.HybridBlock.hybridize()` or not.</span>
            <span class="n">hybridize_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># `mx.cpu()` or `mx.gpu()`.</span>
            <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ctx</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">decoder</span> <span class="o">=</span> <span class="n">LSTMNetworks</span><span class="p">(</span>
            <span class="c1"># is-a `ComputableLoss` or `mxnet.gluon.loss`.</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">computable_loss</span><span class="p">,</span>
            <span class="c1"># `int` of batch size.</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="c1"># `int` of the length of series.</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
            <span class="c1"># `int` of the number of units in hidden layer.</span>
            <span class="n">hidden_n</span><span class="o">=</span><span class="n">hidden_neuron_count</span><span class="p">,</span>
            <span class="c1"># `int` of the number of units in output layer.</span>
            <span class="n">output_n</span><span class="o">=</span><span class="n">output_neuron_count</span><span class="p">,</span>
            <span class="c1"># `float` of dropout rate.</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">dropout_rate</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` </span>
            <span class="c1"># that activates observed data points.</span>
            <span class="n">observed_activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in input gate.</span>
            <span class="n">input_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in forget gate.</span>
            <span class="n">forget_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in output gate.</span>
            <span class="n">output_gate_activation</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in hidden layer.</span>
            <span class="n">hidden_activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
            <span class="c1"># `act_type` in `mxnet.ndarray.Activation` or `mxnet.symbol.Activation` in output layer.</span>
            <span class="n">output_activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
            <span class="c1"># `bool` that means this class has output layer or not.</span>
            <span class="n">output_layer_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># `bool` for using bias or not in output layer(last hidden layer).</span>
            <span class="n">output_no_bias_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># Call `mxnet.gluon.HybridBlock.hybridize()` or not.</span>
            <span class="n">hybridize_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># `mx.cpu()` or `mx.gpu()`.</span>
            <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ctx</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="n">EncoderDecoder</span><span class="p">(</span>
            <span class="c1"># is-a `LSTMNetworks`.</span>
            <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
            <span class="c1"># is-a `LSTMNetworks`.</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="c1"># `int` of batch size.</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="c1"># `int` of the length of series.</span>
            <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len</span><span class="p">,</span>
            <span class="c1"># is-a `ComputableLoss` or `mxnet.gluon.loss`.</span>
            <span class="n">computable_loss</span><span class="o">=</span><span class="n">computable_loss</span><span class="p">,</span>
            <span class="c1"># is-a `mxnet.initializer` for parameters of model. If `None`, it is drawing from the Xavier distribution.</span>
            <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="c1"># `float` of learning rate.</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="c1"># `float` of attenuate the `learning_rate` by a factor of this value every `attenuate_epoch`.</span>
            <span class="n">learning_attenuate_rate</span><span class="o">=</span><span class="n">learning_attenuate_rate</span><span class="p">,</span>
            <span class="c1"># `int` of attenuate the `learning_rate` by a factor of `learning_attenuate_rate` every `attenuate_epoch`.</span>
            <span class="n">attenuate_epoch</span><span class="o">=</span><span class="n">attenuate_epoch</span><span class="p">,</span>
            <span class="c1"># `str` of name of optimizer.</span>
            <span class="n">optimizer_name</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span>
            <span class="c1"># Call `mxnet.gluon.HybridBlock.hybridize()` or not.</span>
            <span class="n">hybridize_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="c1"># `mx.cpu()` or `mx.gpu()`.</span>
            <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ctx</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__computable_loss</span> <span class="o">=</span> <span class="n">computable_loss</span>
        <span class="k">return</span> <span class="n">encoder_decoder_controller</span>

<div class="viewcode-block" id="EncDecAD.learn"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.learn">[docs]</a>    <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteratable_data</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Learn the observed data points</span>
<span class="sd">        for vector representation of the input time-series.</span>

<span class="sd">        Args:</span>
<span class="sd">            iteratable_data:     is-a `IteratableData`.</span>

<span class="sd">        &#39;&#39;&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">iteratable_data</span><span class="p">)</span></div>

<div class="viewcode-block" id="EncDecAD.inference"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.inference">[docs]</a>    <span class="k">def</span> <span class="nf">inference</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">observed_arr</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Infernece by the model.</span>

<span class="sd">        Args:</span>
<span class="sd">            observed_arr:       `np.ndarray` of observed data points.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of inferenced feature points.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">,</span> <span class="n">nd</span><span class="o">.</span><span class="n">NDArray</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">observed_arr</span> <span class="o">=</span> <span class="n">nd</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">__ctx</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">observed_arr</span><span class="p">)</span></div>

<div class="viewcode-block" id="EncDecAD.summarize"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.summarize">[docs]</a>    <span class="k">def</span> <span class="nf">summarize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iteratable_data</span><span class="p">,</span> <span class="n">vectorizable_token</span><span class="p">,</span> <span class="n">sentence_list</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        Summarize input document.</span>

<span class="sd">        Args:</span>
<span class="sd">            iteratable_data:        is-a `IteratableData`.</span>
<span class="sd">            vectorizable_token:     is-a `VectorizableToken`.</span>
<span class="sd">            sentence_list:          `list` of all sentences.</span>
<span class="sd">            limit:                  The number of selected abstract sentence.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            `np.ndarray` of scores.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vectorizable_token</span><span class="p">,</span> <span class="n">VectorizableToken</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span>

        <span class="n">_score_arr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">_test_arr</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_arr</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">iteratable_data</span><span class="o">.</span><span class="n">generate_inferenced_samples</span><span class="p">():</span>
            <span class="n">reconstruced_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inference</span><span class="p">(</span><span class="n">test_arr</span><span class="p">)</span>
            <span class="n">score_arr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__computable_loss</span><span class="p">(</span><span class="n">test_arr</span><span class="p">,</span> <span class="n">reconstruced_arr</span><span class="p">)</span>
            <span class="n">score_arr</span> <span class="o">=</span> <span class="n">score_arr</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">_score_arr</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_score_arr</span> <span class="o">=</span> <span class="n">score_arr</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_score_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">_score_arr</span><span class="p">,</span> <span class="n">score_arr</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">_test_arr</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_test_arr</span> <span class="o">=</span> <span class="n">test_arr</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_test_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">r_</span><span class="p">[</span><span class="n">_test_arr</span><span class="p">,</span> <span class="n">test_arr</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()]</span>

        <span class="n">score_list</span> <span class="o">=</span> <span class="n">_score_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">test_arr</span> <span class="o">=</span> <span class="n">_test_arr</span>
        <span class="n">score_arr</span> <span class="o">=</span> <span class="n">_score_arr</span>

        <span class="n">abstract_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">limit</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__normal_prior_flag</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">key</span> <span class="o">=</span> <span class="n">score_arr</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">key</span> <span class="o">=</span> <span class="n">score_arr</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>

            <span class="n">score</span> <span class="o">=</span> <span class="n">score_list</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
            <span class="n">score_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">score_list</span><span class="p">)</span>

            <span class="n">seq_arr</span> <span class="o">=</span> <span class="n">test_arr</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">token_arr</span> <span class="o">=</span> <span class="n">vectorizable_token</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">seq_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">s</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">token_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">_s</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">token_arr</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

            <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentence</span> <span class="ow">or</span> <span class="n">_s</span> <span class="ow">in</span> <span class="n">sentence</span><span class="p">:</span>
                    <span class="n">abstract_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
                    <span class="n">abstract_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">abstract_list</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">abstract_list</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">limit</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">return</span> <span class="n">abstract_list</span></div>

<div class="viewcode-block" id="EncDecAD.set_readonly"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.set_readonly">[docs]</a>    <span class="k">def</span> <span class="nf">set_readonly</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; setter &#39;&#39;&#39;</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">()</span></div>

<div class="viewcode-block" id="EncDecAD.get_encoder_decoder_controller"><a class="viewcode-back" href="../../../../pysummarization.abstractablesemantics._mxnet.html#pysummarization.abstractablesemantics._mxnet.enc_dec_ad.EncDecAD.get_encoder_decoder_controller">[docs]</a>    <span class="k">def</span> <span class="nf">get_encoder_decoder_controller</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39; getter &#39;&#39;&#39;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__encoder_decoder_controller</span></div>

    <span class="n">encoder_decoder_controller</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="n">get_encoder_decoder_controller</span><span class="p">,</span> <span class="n">set_readonly</span><span class="p">)</span></div>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">pysummarization  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2020, Accel Brain.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>